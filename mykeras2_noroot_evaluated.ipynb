{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using numpy 1.14.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using keras 2.2.0\n",
      "[INFO] Using tensorflow 1.8.0\n",
      "[INFO] Using sklearn 0.19.1\n",
      "[INFO] Current time 2018-07-10 17:03:15.692037\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(2023)\n",
    "import random\n",
    "random.seed(2023)\n",
    "print('[INFO] Using numpy {0}'.format(np.__version__))\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "old_stdout = sys.stdout\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Dropout, Input, BatchNormalization\n",
    "from keras import initializers, regularizers, optimizers, losses\n",
    "#K.set_epsilon(1e-08)\n",
    "print('[INFO] Using keras {0}'.format(keras.__version__))\n",
    "\n",
    "import tensorflow as tf\n",
    "print('[INFO] Using tensorflow {0}'.format(tf.__version__))\n",
    "\n",
    "import sklearn\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "print('[INFO] Using sklearn {0}'.format(sklearn.__version__))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "%matplotlib inline\n",
    "\n",
    "from datetime import datetime\n",
    "print('[INFO] Current time {0}'.format(str(datetime.now())))\n",
    "\n",
    "\n",
    "# ______________________________________________________________________________\n",
    "# Globals\n",
    "nlayers = 12  # 5 (CSC) + 4 (RPC) + 3 (GEM)\n",
    "\n",
    "nvariables = (nlayers * 5) + 8\n",
    "\n",
    "discr_pt_cut = 14.\n",
    "\n",
    "reg_pt_scale = 100.\n",
    "\n",
    "discr_loss_weight = 1.\n",
    "\n",
    "add_noise = True\n",
    "\n",
    "infile_muon = '/scratch/CMS/L1MuonTrigger/P2_9_2_3_patch1/SingleMuon_Toy_2GeV/histos_tba.13.npz'\n",
    "\n",
    "infile_pileup = '/scratch/CMS/L1MuonTrigger/P2_9_2_3_patch1/SingleMuon_Toy_2GeV/histos_tbd.13.npz'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Encoder(object):\n",
    "\n",
    "  def __init__(self, x, y, adjust_scale=0):\n",
    "    if x is not None and y is not None:\n",
    "      assert(x.shape[1] == (nlayers * 6) + 4)\n",
    "      assert(y.shape[1] == 3)\n",
    "      assert(x.shape[0] == y.shape[0])\n",
    "\n",
    "      self.nentries = x.shape[0]\n",
    "      self.x_orig  = x\n",
    "      self.y_orig  = y\n",
    "      self.x_copy  = x.copy()\n",
    "      self.y_copy  = y.copy()\n",
    "\n",
    "      # Get views\n",
    "      self.x_phi   = self.x_copy[:, nlayers*0:nlayers*1]\n",
    "      self.x_theta = self.x_copy[:, nlayers*1:nlayers*2]\n",
    "      self.x_bend  = self.x_copy[:, nlayers*2:nlayers*3]\n",
    "      self.x_ring  = self.x_copy[:, nlayers*3:nlayers*4]\n",
    "      self.x_fr    = self.x_copy[:, nlayers*4:nlayers*5]\n",
    "      self.x_mask  = self.x_copy[:, nlayers*5:nlayers*6].astype(np.bool)  # this makes a copy\n",
    "      self.x_road  = self.x_copy[:, nlayers*6:nlayers*7]  # ipt, ieta, iphi, iphi_corr\n",
    "      self.y_pt    = self.y_copy[:, 0]  # q/pT\n",
    "      self.y_phi   = self.y_copy[:, 1]\n",
    "      self.y_eta   = self.y_copy[:, 2]\n",
    "      \n",
    "      # Make event weight\n",
    "      #self.w       = np.ones(self.y_pt.shape, dtype=np.float32)\n",
    "      self.w       = np.abs(self.y_pt)/0.2 + 1.0\n",
    "      \n",
    "      # Straightness & zone\n",
    "      self.x_straightness = self.x_road[:, 0][:, np.newaxis]\n",
    "      self.x_zone         = self.x_road[:, 1][:, np.newaxis]\n",
    "      \n",
    "      # Subtract median phi from hit phis\n",
    "      #self.x_phi_median    = self.x_road[:, 2] * 32 - 16  # multiply by 'quadstrip' unit (4 * 8)\n",
    "      self.x_phi_median    = self.x_road[:, 2] * 16 - 8  # multiply by 'doublestrip' unit (2 * 8)\n",
    "      self.x_phi_median    = self.x_phi_median[:, np.newaxis]\n",
    "      self.x_phi          -= self.x_phi_median\n",
    "      \n",
    "      # Subtract median theta from hit thetas\n",
    "      self.x_theta_median  = np.nanmedian(self.x_theta[:,:5], axis=1)  # CSC only\n",
    "      self.x_theta_median[np.isnan(self.x_theta_median)] = np.nanmedian(self.x_theta[np.isnan(self.x_theta_median)], axis=1)  # use all\n",
    "      self.x_theta_median  = self.x_theta_median[:, np.newaxis]\n",
    "      self.x_theta        -= self.x_theta_median\n",
    "      \n",
    "      # Standard scales\n",
    "      # + Remove outlier hits by checking hit thetas\n",
    "      if adjust_scale == 0:  # do not adjust\n",
    "        x_theta_tmp = np.abs(self.x_theta) > 10000.0\n",
    "      elif adjust_scale == 1:  # use mean and std\n",
    "        self.x_mean  = np.nanmean(self.x_copy, axis=0)\n",
    "        self.x_std   = np.nanstd(self.x_copy, axis=0)\n",
    "        self.x_std   = self._handle_zero_in_scale(self.x_std)\n",
    "        self.x_copy -= self.x_mean\n",
    "        self.x_copy /= self.x_std\n",
    "        x_theta_tmp = np.abs(self.x_theta) > 1.0\n",
    "      elif adjust_scale == 2:  # adjust by hand\n",
    "        theta_cuts    = np.array((6., 6., 6., 6., 6., 12., 12., 12., 12., 9., 9., 9.), dtype=np.float32)\n",
    "        x_theta_tmp   = np.abs(self.x_theta) > theta_cuts\n",
    "        self.x_phi   *= 0.000991  # GE1/1 dphi linear correlation with q/pT\n",
    "        self.x_theta *= (1/12.)   # 12 integer theta units\n",
    "        self.x_bend  *= 0.188082  # ME1/2 bend linear correlation with q/pT\n",
    "        x_ring_tmp    = self.x_ring.astype(np.int32)\n",
    "        x_ring_tmp    = (x_ring_tmp == 1) | (x_ring_tmp == 4)\n",
    "        self.x_ring[x_ring_tmp] = 0  # ring 1,4 -> 0\n",
    "        self.x_ring[~x_ring_tmp] = 1 # ring 2,3 -> 1\n",
    "        x_fr_tmp      = self.x_fr.astype(np.int32)\n",
    "        x_fr_tmp      = (x_fr_tmp == 0)\n",
    "        self.x_fr[x_fr_tmp] = 0\n",
    "        self.x_fr[~x_fr_tmp] = 1\n",
    "      elif adjust_scale == 3:  # adjust by hand #2\n",
    "        #theta_cuts    = np.array((6., 6., 6., 6., 6., 12., 12., 12., 12., 9., 9., 9.), dtype=np.float32)\n",
    "        theta_cuts    = np.array((6., 6., 6., 6., 6., 10., 10., 10., 10., 8., 8., 8.), dtype=np.float32)\n",
    "        x_theta_tmp   = np.abs(self.x_theta) > theta_cuts\n",
    "        x_ring_tmp    = self.x_ring.astype(np.int32)\n",
    "        x_ring_tmp    = (x_ring_tmp == 1) | (x_ring_tmp == 4)\n",
    "        self.x_ring[x_ring_tmp] = 0  # ring 1,4 -> 0\n",
    "        self.x_ring[~x_ring_tmp] = 1 # ring 2,3 -> 1\n",
    "        x_fr_tmp      = self.x_fr.astype(np.int32)\n",
    "        x_fr_tmp      = (x_fr_tmp == 0)\n",
    "        self.x_fr[x_fr_tmp] = 0\n",
    "        self.x_fr[~x_fr_tmp] = 1\n",
    "        s = [ 0.00528005,  0.01100854, -0.01955833, -0.01326062, -0.00839341,\n",
    "              0.01209313, -0.02546741, -0.011541  , -0.00734255,  0.00393156,\n",
    "             -0.02459449,  1.        ,  0.55500895,  0.50743203,  1.4219028 ,\n",
    "              1.35162982,  0.93576706,  0.19965793,  0.29495697,  0.35250728,\n",
    "              0.38013349,  0.50885451,  0.66930139,  1.        ,  0.81924683,\n",
    "              0.47289819,  1.67281557,  1.1339659 ,  1.13266964,  1.        ,\n",
    "              1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
    "              1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
    "              1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
    "              1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
    "              1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
    "              1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
    "              1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
    "              1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
    "              1.        ,  1.        ,  1.        ,  1.        ,  1.        ,  1.        ]\n",
    "        self.x_copy *= s\n",
    "      \n",
    "      # Remove outlier hits by checking hit thetas\n",
    "      self.x_phi  [x_theta_tmp] = np.nan\n",
    "      self.x_theta[x_theta_tmp] = np.nan\n",
    "      self.x_bend [x_theta_tmp] = np.nan\n",
    "      self.x_ring [x_theta_tmp] = np.nan\n",
    "      self.x_fr   [x_theta_tmp] = np.nan\n",
    "      self.x_mask [x_theta_tmp] = 1.0\n",
    "      \n",
    "      # Add variables: straightness, zone, theta_median and mode variables\n",
    "      self.x_straightness = np.abs(self.x_straightness - 6.) / 6.  # scaled to [0,1]\n",
    "      self.x_zone         = (self.x_zone - 0.) / 5.  # scaled to [0,1]\n",
    "      self.x_theta_median = (self.x_theta_median - 3.) / 83.  # scaled to [0,1]\n",
    "      hits_to_station = np.array((5,1,2,3,4,1,2,3,4,5,2,5), dtype=np.int32)  # '5' denotes ME1/1\n",
    "      assert(len(hits_to_station) == nlayers)\n",
    "      self.x_mode_vars = np.zeros((self.nentries, 5), dtype=np.bool)\n",
    "      self.x_mode_vars[:,0] = np.any(self.x_mask[:,hits_to_station == 5] == 0, axis=1)\n",
    "      self.x_mode_vars[:,1] = np.any(self.x_mask[:,hits_to_station == 1] == 0, axis=1)\n",
    "      self.x_mode_vars[:,2] = np.any(self.x_mask[:,hits_to_station == 2] == 0, axis=1)\n",
    "      self.x_mode_vars[:,3] = np.any(self.x_mask[:,hits_to_station == 3] == 0, axis=1)\n",
    "      self.x_mode_vars[:,4] = np.any(self.x_mask[:,hits_to_station == 4] == 0, axis=1)\n",
    "      \n",
    "      # Remove NaN\n",
    "      #np.nan_to_num(self.x_copy, copy=False)\n",
    "      self.x_copy[np.isnan(self.x_copy)] = 0.0\n",
    "\n",
    "  # Copied from scikit-learn\n",
    "  def _handle_zero_in_scale(self, scale):\n",
    "    scale[scale == 0.0] = 1.0\n",
    "    return scale\n",
    "\n",
    "  def get_x(self):\n",
    "    #x_new = self.x_phi\n",
    "    x_new = np.hstack((self.x_phi, self.x_theta, self.x_bend, self.x_ring, self.x_fr, self.x_straightness, self.x_zone, self.x_theta_median, self.x_mode_vars))\n",
    "    return x_new\n",
    "\n",
    "  def get_x_mask(self):\n",
    "    x_mask = self.x_mask.copy()\n",
    "    return x_mask\n",
    "\n",
    "  def get_y(self):\n",
    "    y_new = self.y_pt.copy()\n",
    "    return y_new\n",
    "\n",
    "  def get_w(self):\n",
    "    w_new = self.w.copy()\n",
    "    return w_new\n",
    "\n",
    "  def save_encoder(self, filepath):\n",
    "    np.savez_compressed(filepath, x_mean=self.x_mean, x_std=self.x_std)\n",
    "\n",
    "  def load_endcoder(self, filepath):\n",
    "    loaded = np.load(filepath)\n",
    "    self.x_mean = loaded['x_mean']\n",
    "    self.x_std = loaded['x_std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "# ______________________________________________________________________________\n",
    "# New leaky relu\n",
    "def NewLeakyReLU(x, alpha=0., max_value=None):\n",
    "  return K.relu(x, alpha=alpha, max_value=max_value)\n",
    "\n",
    "# ______________________________________________________________________________\n",
    "# New tanh\n",
    "def NewTanh(x):\n",
    "  return K.tanh(x)\n",
    "  #return 1.7159 * K.tanh(x * 2./3.)\n",
    "  #return K.clip(x, -1., 1.)\n",
    "\n",
    "# ______________________________________________________________________________\n",
    "# Huber loss\n",
    "def huber_loss(y_true, y_pred, delta=1.345):\n",
    "  x = K.abs(y_true - y_pred)\n",
    "  squared_loss = 0.5*K.square(x)\n",
    "  absolute_loss = delta * (x - 0.5*delta)\n",
    "  #xx = K.switch(x < delta, squared_loss, absolute_loss)\n",
    "  xx = tf.where(x < delta, squared_loss, absolute_loss)  # needed for tensorflow\n",
    "  return K.mean(xx, axis=-1)\n",
    "\n",
    "def masked_huber_loss(y_true, y_pred, delta=1.345):\n",
    "  x = K.abs(y_true - y_pred)\n",
    "  squared_loss = 0.5*K.square(x)\n",
    "  absolute_loss = delta * (x - 0.5*delta)\n",
    "  #xx = K.switch(x < delta, squared_loss, absolute_loss)\n",
    "  xx = tf.where(x < delta, squared_loss, absolute_loss)  # needed for tensorflow\n",
    "\n",
    "  mask_value = 100.\n",
    "  mask = K.not_equal(y_true, mask_value)\n",
    "  mask = K.cast(mask, K.floatx())\n",
    "  xx *= mask\n",
    "  xx /= K.mean(mask)\n",
    "  return K.mean(xx, axis=-1)\n",
    "\n",
    "#def masked_huber_loss(y_true, y_pred, delta=1.345):\n",
    "#  mask_value = 100.\n",
    "#  mask_alpha = 0.02\n",
    "#  mask_target = 0.5 * reg_pt_scale\n",
    "#  mask = K.equal(y_true, mask_value)\n",
    "#  \n",
    "#  #x = K.abs(y_true - y_pred)\n",
    "#  x = tf.where(mask, mask_alpha * K.abs(mask_target - K.abs(y_pred)), K.abs(y_true - y_pred))\n",
    "#  squared_loss = 0.5*K.square(x)\n",
    "#  absolute_loss = delta * (x - 0.5*delta)\n",
    "#  #xx = K.switch(x < delta, squared_loss, absolute_loss)\n",
    "#  xx = tf.where(x < delta, squared_loss, absolute_loss)  # needed for tensorflow\n",
    "#  return K.mean(xx, axis=-1)\n",
    "\n",
    "\n",
    "# ______________________________________________________________________________\n",
    "# Binary crossentropy\n",
    "def masked_binary_crossentropy(y_true, y_pred, from_logits=False):\n",
    "  target, output = y_true, y_pred\n",
    "\n",
    "  # transform back to logits\n",
    "  if not from_logits:\n",
    "    output = K.clip(output, K.epsilon(), 1 - K.epsilon())\n",
    "    output = K.log(output / (1 - output))\n",
    "  \n",
    "  xx =  tf.nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n",
    "  #xx =  tf.nn.weighted_cross_entropy_with_logits(targets=target, logits=output, pos_weight=0.5)  # pos_weight < 1 decreases the false positive count\n",
    "\n",
    "  mask_value = 100.\n",
    "  mask = K.not_equal(y_true, mask_value)\n",
    "  mask = K.cast(mask, K.floatx())\n",
    "  xx *= mask\n",
    "  xx /= K.mean(mask)\n",
    "  return K.mean(xx, axis=-1)\n",
    "\n",
    "\n",
    "# ______________________________________________________________________________\n",
    "# Learning rate decay by epoch number\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "  if (epoch % 10) == 0:\n",
    "    lr = K.get_value(model.optimizer.lr)\n",
    "    K.set_value(model.optimizer.lr, lr*0.95)\n",
    "    print(\"lr changed to {}\".format(lr*0.95))\n",
    "  return K.get_value(model.optimizer.lr)\n",
    "\n",
    "lr_decay = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "\n",
    "# ______________________________________________________________________________\n",
    "# Custom objects\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "\n",
    "get_custom_objects().update({'masked_huber_loss': masked_huber_loss, 'masked_binary_crossentropy': masked_binary_crossentropy, 'NewLeakyReLU': NewLeakyReLU, 'NewTanh': NewTanh})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading muon data ...\n",
      "[INFO] Loaded the variables with shape (3643811, 76)\n",
      "[INFO] Loaded the parameters with shape (3643811, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uf/jlow/jftest2/miniconda3/envs/tensorflow_conda/lib/python2.7/site-packages/numpy/lib/function_base.py:4033: RuntimeWarning: All-NaN slice encountered\n",
      "  r = func(a, **kwargs)\n",
      "/home/uf/jlow/jftest2/miniconda3/envs/tensorflow_conda/lib/python2.7/site-packages/ipykernel_launcher.py:75: RuntimeWarning: invalid value encountered in greater\n"
     ]
    }
   ],
   "source": [
    "#### Load data ####\n",
    "\n",
    "def muon_data():\n",
    "  try:\n",
    "    print('[INFO] Loading muon data ...')\n",
    "    loaded = np.load(infile_muon)\n",
    "    the_variables = loaded['variables']\n",
    "    the_parameters = loaded['parameters']\n",
    "    print('[INFO] Loaded the variables with shape {0}'.format(the_variables.shape))\n",
    "    print('[INFO] Loaded the parameters with shape {0}'.format(the_parameters.shape))\n",
    "  except:\n",
    "    print('[ERROR] Failed to load data from file: {0}'.format(infile_muon))\n",
    "\n",
    "  encoder = Encoder(the_variables, the_parameters, adjust_scale=3)\n",
    "  x, y, w, x_mask = encoder.get_x(), encoder.get_y(), encoder.get_w(), encoder.get_x_mask()\n",
    "  assert np.isfinite(x).all()\n",
    "\n",
    "  # Split dataset in training and testing\n",
    "  x_train, x_test, y_train, y_test, w_train, w_test, x_mask_train, x_mask_test = train_test_split(x, y, w, x_mask, test_size=0.3)\n",
    "  return x_train, x_test, y_train, y_test, w_train, w_test, x_mask_train, x_mask_test\n",
    "\n",
    "# ______________________________________________________________________________\n",
    "x_train, x_test, y_train, y_test, w_train, w_test, x_mask_train, x_mask_test = muon_data()\n",
    "\n",
    "# Add output nodes\n",
    "labels = np.where(np.abs(1.0/y_train) > discr_pt_cut, 1., 100.)  # mask_value is set to 100\n",
    "y_train = [y_train, labels.astype(np.float32)]\n",
    "\n",
    "labels = np.where(np.abs(1.0/y_test) > discr_pt_cut, 1., 100.)  # mask_value is set to 100\n",
    "y_test = [y_test, labels.astype(np.float32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading pileup data ...\n",
      "[INFO] Loaded the variables with shape (171550, 76)\n",
      "[INFO] Loaded the auxiliary info with shape (171550, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uf/jlow/jftest2/miniconda3/envs/tensorflow_conda/lib/python2.7/site-packages/ipykernel_launcher.py:75: RuntimeWarning: invalid value encountered in greater\n"
     ]
    }
   ],
   "source": [
    "#### Load data (pileup) ####\n",
    "\n",
    "def pileup_data():\n",
    "  try:\n",
    "    print('[INFO] Loading pileup data ...')\n",
    "    loaded = np.load(infile_pileup)\n",
    "    the_variables = loaded['variables']\n",
    "    the_parameters = np.zeros((the_variables.shape[0], 3), dtype=np.float32)\n",
    "    the_auxiliaries = loaded['aux']\n",
    "    print('[INFO] Loaded the variables with shape {0}'.format(the_variables.shape))\n",
    "    print('[INFO] Loaded the auxiliary info with shape {0}'.format(the_auxiliaries.shape))\n",
    "  except:\n",
    "    print('[ERROR] Failed to load data from file: {0}'.format(infile_pileup))\n",
    "\n",
    "  sel = the_auxiliaries[:,2] > discr_pt_cut\n",
    "  the_variables = the_variables[~sel]\n",
    "  the_parameters = the_parameters[~sel]\n",
    "  the_auxiliaries = the_auxiliaries[~sel]\n",
    "\n",
    "  encoder = Encoder(the_variables, the_parameters, adjust_scale=3)\n",
    "  x, y, w, x_mask = encoder.get_x(), encoder.get_y(), encoder.get_w(), encoder.get_x_mask()\n",
    "  aux = the_auxiliaries  # jobid, ievt, highest_part_pt, highest_track_pt\n",
    "  assert np.isfinite(x).all()\n",
    "\n",
    "  # Split dataset in training and testing\n",
    "  split = the_auxiliaries[:,0] < 50.\n",
    "  x_train, x_test, aux_train, aux_test = x[~split], x[split], aux[~split], aux[split]\n",
    "  return x_train, x_test, aux_train, aux_test\n",
    "\n",
    "# ______________________________________________________________________________\n",
    "x_adv_train, x_adv_test, aux_adv_train, aux_adv_test = pileup_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### Create a model ####\n",
    "\n",
    "# See https://keras.io/models/about-keras-models/\n",
    "#     https://keras.io/layers/about-keras-layers/\n",
    "#     https://keras.io/getting-started/functional-api-guide/#getting-started-with-the-keras-functional-api\n",
    "\n",
    "def create_model():\n",
    "  inputs = Input(shape=(nvariables,), dtype='float32')\n",
    "\n",
    "  x = Dense(64, activation='tanh', kernel_initializer='glorot_uniform', kernel_regularizer=regularizers.l2(0.0000))(inputs)\n",
    "  #x = Dropout(0.2)(x)\n",
    "  x = Dense(32, activation='tanh', kernel_initializer='glorot_uniform', kernel_regularizer=regularizers.l2(0.0000))(x)\n",
    "  #x = Dropout(0.2)(x)\n",
    "  x = Dense(16, activation='tanh', kernel_initializer='glorot_uniform', kernel_regularizer=regularizers.l2(0.0000))(x)\n",
    "  #x = Dropout(0.2)(x)\n",
    "\n",
    "  regr = Dense(1, activation='linear', kernel_initializer='glorot_uniform', name='regr')(x)\n",
    "  discr = Dense(1, activation='sigmoid', kernel_initializer='glorot_uniform', name='discr')(x)\n",
    "\n",
    "  # This creates a model that includes\n",
    "  # the Input layer, three Dense layers and the Output layer\n",
    "  model = Model(inputs=inputs, outputs=[regr, discr])\n",
    "\n",
    "  # Set loss and optimizers\n",
    "  #binary_crossentropy = losses.binary_crossentropy\n",
    "  #mean_squared_error = losses.mean_squared_error\n",
    "\n",
    "  adam = optimizers.Adam(lr=0.00113)\n",
    "  #adam = optimizers.Adam(lr=0.001)  # default\n",
    "  #adam = optimizers.Adam(lr=0.01)\n",
    "  #adam = optimizers.Adam(lr=0.001, amsgrad=True)\n",
    "\n",
    "  # Compile\n",
    "  model.compile(optimizer=adam,\n",
    "    loss={'regr': masked_huber_loss, 'discr': masked_binary_crossentropy},\n",
    "    loss_weights={'regr': 1.0, 'discr': discr_loss_weight},\n",
    "    #metrics={'regr': ['acc', 'mse', 'mae'], 'discr': ['acc',]}\n",
    "    )\n",
    "  return model\n",
    "\n",
    "def create_model_sequential():\n",
    "  model = Sequential()\n",
    "  model.add(Dense(64, input_dim=nvariables, activation='tanh', kernel_initializer='glorot_uniform', kernel_regularizer=regularizers.l2(0.0000)))\n",
    "  #model.add(Dropout(0.2))\n",
    "  model.add(Dense(32, activation='tanh', kernel_initializer='glorot_uniform', kernel_regularizer=regularizers.l2(0.0000)))\n",
    "  #model.add(Dropout(0.2))\n",
    "  model.add(Dense(16, activation='tanh', kernel_initializer='glorot_uniform', kernel_regularizer=regularizers.l2(0.0000)))\n",
    "  #model.add(Dropout(0.2))\n",
    "  model.add(Dense(1, activation='linear', kernel_initializer='glorot_uniform'))\n",
    "  \n",
    "  adam = optimizers.Adam(lr=0.001)\n",
    "  model.compile(loss=huber_loss, optimizer=adam, metrics=['acc'])\n",
    "  return model\n",
    "\n",
    "def save_model(model):\n",
    "  # Store model to file\n",
    "  model.summary()\n",
    "  model.save('model.h5')\n",
    "  model.save_weights('model_weights.h5')\n",
    "\n",
    "  # Store model to json\n",
    "  import json\n",
    "  with open('model.json', 'w') as outfile:\n",
    "    outfile.write(model.to_json())\n",
    "  return\n",
    "\n",
    "# ______________________________________________________________________________\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### Training Functions ####\n",
    "\n",
    "# from https://github.com/keras-team/keras/blob/master/keras/utils/generic_utils.py\n",
    "def slice_arrays(arrays, start=None, stop=None):\n",
    "    \"\"\"Slices an array or list of arrays.\n",
    "    This takes an array-like, or a list of\n",
    "    array-likes, and outputs:\n",
    "        - arrays[start:stop] if `arrays` is an array-like\n",
    "        - [x[start:stop] for x in arrays] if `arrays` is a list\n",
    "    Can also work on list/array of indices: `_slice_arrays(x, indices)`\n",
    "    # Arguments\n",
    "        arrays: Single array or list of arrays.\n",
    "        start: can be an integer index (start index)\n",
    "            or a list/array of indices\n",
    "        stop: integer (stop index); should be None if\n",
    "            `start` was a list.\n",
    "    # Returns\n",
    "        A slice of the array(s).\n",
    "    \"\"\"\n",
    "    if arrays is None:\n",
    "        return [None]\n",
    "    elif isinstance(arrays, list):\n",
    "        if hasattr(start, '__len__'):\n",
    "            # hdf5 datasets only support list objects as indices\n",
    "            if hasattr(start, 'shape'):\n",
    "                start = start.tolist()\n",
    "            return [None if x is None else x[start] for x in arrays]\n",
    "        else:\n",
    "            return [None if x is None else x[start:stop] for x in arrays]\n",
    "    else:\n",
    "        if hasattr(start, '__len__'):\n",
    "            if hasattr(start, 'shape'):\n",
    "                start = start.tolist()\n",
    "            return arrays[start]\n",
    "        elif hasattr(start, '__getitem__'):\n",
    "            return arrays[start:stop]\n",
    "        else:\n",
    "            return [None]\n",
    "\n",
    "\n",
    "def merge_arrays(arrays, arrays_to_add):\n",
    "    if isinstance(arrays, list):\n",
    "        return [None if x is None else np.concatenate((x,y)) for (x,y) in zip(arrays, arrays_to_add)]\n",
    "    else:\n",
    "        return [None]\n",
    "\n",
    "# from https://github.com/keras-team/keras/blob/master/keras/engine/training_utils.py\n",
    "def make_batches(size, batch_size):\n",
    "    \"\"\"Returns a list of batch indices (tuples of indices).\n",
    "    # Arguments\n",
    "        size: Integer, total size of the data to slice into batches.\n",
    "        batch_size: Integer, batch size.\n",
    "    # Returns\n",
    "        A list of tuples of array indices.\n",
    "    \"\"\"\n",
    "    num_batches = (size + batch_size - 1) // batch_size  # round up\n",
    "    return [(i * batch_size, min(size, (i + 1) * batch_size))\n",
    "            for i in range(num_batches)]\n",
    "\n",
    "# ______________________________________________________________________________\n",
    "# from https://github.com/keras-team/keras/blob/2.0.5/keras/engine/training.py\n",
    "\n",
    "import copy\n",
    "from keras import callbacks as cbks\n",
    "from keras.utils.generic_utils import Progbar\n",
    "\n",
    "def train(model, x, y, x_adv, aux_adv, batch_size=None, epochs=1, verbose=1, callbacks=None,\n",
    "          validation_split=0., shuffle=True, class_weight=None, sample_weight=None):\n",
    "  \n",
    "  # Validate user data.\n",
    "  x, y, sample_weights = model._standardize_user_data(\n",
    "    x, y,\n",
    "    sample_weight=sample_weight,\n",
    "    class_weight=class_weight,\n",
    "    batch_size=batch_size)\n",
    "  \n",
    "  y = [y[0] * reg_pt_scale, y[1]]\n",
    "  \n",
    "  # Prepare input arrays\n",
    "  if model.uses_learning_phase and not isinstance(K.learning_phase(), int):\n",
    "    ins = x + y + sample_weights + [1.]\n",
    "  else:\n",
    "    ins = x + y + sample_weights\n",
    "\n",
    "  #print('[INFO] ins shapes: {0}'.format([xx.shape for xx in ins]))\n",
    "  \n",
    "  # Prepare validation data.\n",
    "  do_validation = False\n",
    "  if validation_split and 0. < validation_split < 1.:\n",
    "    do_validation = True\n",
    "    if hasattr(x[0], 'shape'):\n",
    "      split_at = int(x[0].shape[0] * (1. - validation_split))\n",
    "    else:\n",
    "      split_at = int(len(x[0]) * (1. - validation_split))\n",
    "    x, val_x = (slice_arrays(x, 0, split_at), slice_arrays(x, split_at))\n",
    "    y, val_y = (slice_arrays(y, 0, split_at), slice_arrays(y, split_at))\n",
    "    sample_weights, val_sample_weights = (slice_arrays(sample_weights, 0, split_at), slice_arrays(sample_weights, split_at))\n",
    "    if model.uses_learning_phase and not isinstance(K.learning_phase(), int):\n",
    "      val_ins = val_x + val_y + val_sample_weights + [0.]\n",
    "    else:\n",
    "      val_ins = val_x + val_y + val_sample_weights\n",
    "  else:\n",
    "    val_ins = []\n",
    "\n",
    "  # logic from `_fit_loop()`\n",
    "  num_train_samples = x[0].shape[0]\n",
    "  index_array = np.arange(num_train_samples)\n",
    "  num_test_samples = val_x[0].shape[0]\n",
    "  val_index_array = np.arange(num_test_samples)\n",
    "  \n",
    "  # Callbacks\n",
    "  out_labels = model.metrics_names\n",
    "  if do_validation:\n",
    "    callback_metrics = copy.copy(out_labels) + ['val_' + n for n in out_labels]\n",
    "  else:\n",
    "    callback_metrics = copy.copy(out_labels)\n",
    "\n",
    "  model.history = cbks.History()\n",
    "  callbacks = [cbks.BaseLogger()] + (callbacks or []) + [model.history]\n",
    "  if verbose:\n",
    "    callbacks += [cbks.ProgbarLogger()]\n",
    "  callbacks = cbks.CallbackList(callbacks)\n",
    "  callback_model = model\n",
    "  callbacks.set_model(callback_model)\n",
    "  callbacks.set_params({\n",
    "      'batch_size': batch_size,\n",
    "      'epochs': epochs,\n",
    "      'samples': num_train_samples,\n",
    "      'verbose': verbose,\n",
    "      'do_validation': do_validation,\n",
    "      'metrics': callback_metrics or [],\n",
    "  })\n",
    "  callbacks.on_train_begin()\n",
    "  callback_model.stop_training = False\n",
    "  for cbk in callbacks:\n",
    "      cbk.validation_data = val_ins\n",
    "  \n",
    "  \n",
    "  # Loop over epochs\n",
    "  for epoch in xrange(epochs):\n",
    "    epoch_logs = {}\n",
    "    callbacks.on_epoch_begin(epoch)\n",
    "    \n",
    "    if shuffle:\n",
    "      np.random.shuffle(index_array)\n",
    "      #np.random.shuffle(val_index_array)\n",
    "    \n",
    "    batches = make_batches(num_train_samples, batch_size)\n",
    "    \n",
    "    # Loop over batches\n",
    "    for batch_index, (batch_start, batch_end) in enumerate(batches):\n",
    "      batch_ids = index_array[batch_start:batch_end]\n",
    "      if ins and isinstance(ins[-1], float):\n",
    "        # Do not slice the training phase flag.\n",
    "        ins_batch = slice_arrays(ins[:-1], batch_ids) + [ins[-1]]\n",
    "        assert isinstance(ins_batch, list) and len(ins_batch) == 1 + 2 + 2 + 1\n",
    "      else:\n",
    "        ins_batch = slice_arrays(ins, batch_ids)\n",
    "        assert isinstance(ins_batch, list) and len(ins_batch) == 1 + 2 + 2\n",
    "      \n",
    "      # Add noise (pileup)\n",
    "      if add_noise:\n",
    "        #noise = x_adv[np.random.randint(0, x_adv.shape[0], ins_batch[0].shape[0])]\n",
    "        #noise_reg = np.zeros_like(ins_batch[1]) + 100.  # mask_value is set to 100\n",
    "        #noise_discr = np.zeros_like(ins_batch[2])\n",
    "        #noise_reg_w = np.ones_like(ins_batch[3])\n",
    "        #noise_discr_w = np.ones_like(ins_batch[3])\n",
    "        n = np.sum(np.equal(ins_batch[2],1.))\n",
    "        noise = x_adv[np.random.randint(0, x_adv.shape[0], n)]\n",
    "        noise_reg = np.zeros((n,1)) + 100.  # mask_value is set to 100\n",
    "        noise_discr = np.zeros((n,1))\n",
    "        noise_reg_w = np.ones((n,))\n",
    "        noise_discr_w = np.ones((n,))\n",
    "        ins_noise = [noise, noise_reg, noise_discr, noise_reg_w, noise_discr_w]\n",
    "        if ins and isinstance(ins[-1], float):\n",
    "          ins_batch = merge_arrays(ins_batch[:-1], ins_noise) + [ins_batch[-1]]\n",
    "        else:\n",
    "          ins_batch = merge_arrays(ins_batch, ins_noise)\n",
    "      \n",
    "      batch_logs = {}\n",
    "      batch_logs['batch'] = batch_index\n",
    "      batch_logs['size'] = len(batch_ids)\n",
    "      callbacks.on_batch_begin(batch_index, batch_logs)\n",
    "      \n",
    "      # Magic\n",
    "      model._make_train_function()\n",
    "      f = model.train_function\n",
    "      outs = f(ins_batch)\n",
    "      \n",
    "      if not isinstance(outs, list):\n",
    "        outs = [outs]\n",
    "      for l, o in zip(out_labels, outs):\n",
    "        batch_logs[l] = o\n",
    "      \n",
    "      callbacks.on_batch_end(batch_index, batch_logs)\n",
    "      if callback_model.stop_training:\n",
    "        break\n",
    "      \n",
    "      if batch_index == len(batches) - 1:  # Last batch.\n",
    "        if do_validation:\n",
    "          # logic from `_test_loop()`\n",
    "          val_batches = make_batches(num_test_samples, batch_size)\n",
    "          val_outs = []\n",
    "          if verbose == 1:\n",
    "            progbar = Progbar(target=num_test_samples)\n",
    "          \n",
    "          for val_batch_index, (val_batch_start, val_batch_end) in enumerate(val_batches):\n",
    "            val_batch_ids = val_index_array[val_batch_start:val_batch_end]\n",
    "            if isinstance(val_ins[-1], float):\n",
    "              # Do not slice the training phase flag.\n",
    "              val_ins_batch = slice_arrays(val_ins[:-1], val_batch_ids) + [val_ins[-1]]\n",
    "            else:\n",
    "              val_ins_batch = slice_arrays(val_ins, val_batch_ids)\n",
    "            \n",
    "            # Magic\n",
    "            model._make_test_function()\n",
    "            val_f = model.test_function\n",
    "            val_batch_outs = val_f(val_ins_batch)\n",
    "            \n",
    "            if isinstance(val_batch_outs, list):\n",
    "              if val_batch_index == 0:\n",
    "                for i, val_batch_out in enumerate(val_batch_outs):\n",
    "                  val_outs.append(0.)\n",
    "              for i, val_batch_out in enumerate(val_batch_outs):\n",
    "                val_outs[i] += val_batch_out * len(val_batch_ids)\n",
    "            else:\n",
    "              if val_batch_index == 0:\n",
    "                val_outs.append(0.)\n",
    "              val_outs[0] += val_batch_outs * len(val_batch_ids)\n",
    "            \n",
    "            if verbose == 1:\n",
    "              progbar.update(val_batch_end)\n",
    "            \n",
    "          if not isinstance(val_outs, list):\n",
    "            val_outs = [val_outs]\n",
    "          # Same labels assumed.\n",
    "          for l, o in zip(out_labels, val_outs):\n",
    "            o /= num_test_samples\n",
    "            epoch_logs['val_' + l] = o\n",
    "            \n",
    "    callbacks.on_epoch_end(epoch, epoch_logs)\n",
    "    if callback_model.stop_training:\n",
    "      break\n",
    "\n",
    "  callbacks.on_train_end()\n",
    "  return model.history\n",
    "\n",
    "# ______________________________________________________________________________\n",
    "def predict(model, x):\n",
    "  outs = model.predict(x)\n",
    "  outs[0] /= reg_pt_scale\n",
    "  return outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Begin training ...\n",
      "[INFO] Time elapsed: 933.183779955 sec\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 68)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           4416        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           2080        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 16)           528         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "regr (Dense)                    (None, 1)            17          dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "discr (Dense)                   (None, 1)            17          dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 7,058\n",
      "Trainable params: 7,058\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "[INFO] Done training.\n",
      "[INFO] Model is saved as model.h5, model.json and model_weights.h5\n"
     ]
    }
   ],
   "source": [
    "#### Training ####\n",
    "\n",
    "print('[INFO] Begin training ...')\n",
    "assert keras.backend.backend() == 'tensorflow'\n",
    "\n",
    "start_time = time.time()\n",
    "sys.stdout = open('keras_output_1.txt', 'w')\n",
    "#history = model.fit(x_train, y_train, epochs=20, validation_split=0.1, batch_size=256, verbose=1)\n",
    "#history = model.fit(x_train, y_train, epochs=200, validation_split=0.1, batch_size=256, callbacks=[lr_decay], verbose=0)\n",
    "history = train(model, x_train, y_train, x_adv_train, aux_adv_train, epochs=10, validation_split=0.1, batch_size=128, verbose=1)\n",
    "#history = train(model, x_train, y_train, x_adv_train, aux_adv_train, epochs=300, validation_split=0.1, batch_size=128, callbacks=[lr_decay], verbose=1)\n",
    "sys.stdout.close()\n",
    "sys.stdout = old_stdout\n",
    "print('[INFO] Time elapsed: {0} sec'.format(time.time() - start_time))\n",
    "\n",
    "save_model(model)\n",
    "print('[INFO] Done training.')\n",
    "print('[INFO] Model is saved as model.h5, model.json and model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093144/1093144 [==============================] - 2s 2us/step\n",
      "[INFO] loss and metrics: [30.1234117574252, 30.09072832870927, 0.032683441041969394]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### Evaluation ####\n",
    "\n",
    "#loss_and_metrics = model.evaluate(x_test, y_test, sample_weight=w_test, batch_size=1000)\n",
    "loss_and_metrics = model.evaluate(x_test, y_test, batch_size=1000)\n",
    "print('[INFO] loss and metrics: {0}'.format(loss_and_metrics))\n",
    "\n",
    "# Loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['regr_loss'])\n",
    "plt.plot(history.history['val_regr_loss'])\n",
    "plt.title('regr loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['discr_loss'])\n",
    "plt.plot(history.history['val_discr_loss'])\n",
    "plt.title('discr loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "## Mean Squared Error\n",
    "#plt.plot(history.history['regr_mean_squared_error'])\n",
    "#plt.plot(history.history['val_regr_mean_squared_error'])\n",
    "#plt.title('regr mse')\n",
    "#plt.ylabel('mse')\n",
    "#plt.xlabel('epoch')\n",
    "#plt.legend(['train', 'validation'], loc='upper left')\n",
    "#plt.show()\n",
    "\n",
    "## Mean Absolute Error\n",
    "#plt.plot(history.history['regr_mean_absolute_error'])\n",
    "#plt.plot(history.history['val_regr_mean_absolute_error'])\n",
    "#plt.title('regr mae')\n",
    "#plt.ylabel('mae')\n",
    "#plt.xlabel('epoch')\n",
    "#plt.legend(['train', 'validation'], loc='upper left')\n",
    "#plt.show()\n",
    "\n",
    "## Accuracy\n",
    "#plt.plot(history.history['discr_acc'])\n",
    "#plt.plot(history.history['val_discr_acc'])\n",
    "#plt.title('discr accuracy')\n",
    "#plt.ylabel('accuracy')\n",
    "#plt.xlabel('epoch')\n",
    "#plt.legend(['train', 'validation'], loc='upper left')\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Make plots ####\n",
    "\n",
    "from keras.models import load_model\n",
    "import ROOT\n",
    "\n",
    "# Load model\n",
    "model_file = 'model.h5'\n",
    "model_weights_file = 'model_weights.h5'\n",
    "\n",
    "loaded_model = load_model(model_file)\n",
    "loaded_model.load_weights(model_weights_file)\n",
    "\n",
    "# Set styles\n",
    "ROOT.gROOT.LoadMacro(\"tdrstyle.C\")\n",
    "ROOT.gROOT.ProcessLine(\"setTDRStyle();\")\n",
    "ROOT.gStyle.SetPalette(57)  # kBird\n",
    "ROOT.gStyle.SetMarkerStyle(1)\n",
    "ROOT.gStyle.SetEndErrorSize(0)\n",
    "ROOT.gStyle.SetPadGridX(True)\n",
    "ROOT.gStyle.SetPadGridY(True)\n",
    "\n",
    "nentries_test = x_test.shape[0]/10\n",
    "#nentries_test = 100000\n",
    "\n",
    "y_test_meas = predict(loaded_model, x_test[:nentries_test, :])\n",
    "\n",
    "y_adv_test = [np.zeros((x_adv_test.shape[0],1), dtype=np.float32), np.zeros((x_adv_test.shape[0],1), dtype=np.float32)]\n",
    "y_adv_test_meas = predict(loaded_model, x_adv_test)\n",
    "\n",
    "print y_test[:nentries_test]\n",
    "print y_test_meas\n",
    "print y_adv_test_meas"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# For regression\n",
    "h1 = ROOT.TH1F(\"h1\", \"h1\", 300, -0.3, 0.3)\n",
    "h2a = ROOT.TH2F(\"h2a\", \"h2a\", 100, -0.5, 0.5, 300, -0.3, 0.3)\n",
    "h2b = ROOT.TH2F(\"h2b\", \"h2b\", 100, -0.5, 0.5, 300, -0.5, 0.5)\n",
    "h2c = ROOT.TH2F(\"h2c\", \"h2c\", 100, -0.5, 0.5, 400, -2, 2)\n",
    "h2d = ROOT.TH2F(\"h2d\", \"h2d\", 100, -0.5, 0.5, 400, -2, 2)\n",
    "h2e = ROOT.TH2F(\"h2e\", \"h2e\", 100, 0., 0.5, 400, -2, 2)\n",
    "\n",
    "for i in xrange(nentries_test):\n",
    "  y_true = y_test[0][i]\n",
    "  y_meas = y_test_meas[0][i]\n",
    "  h1.Fill(y_meas - y_true)\n",
    "  h2a.Fill(y_true, y_meas - y_true) \n",
    "  h2b.Fill(y_true, y_meas)\n",
    "  h2c.Fill(y_true, (y_meas - y_true)/abs(y_true))\n",
    "  h2d.Fill(y_true, (abs(1.0/y_meas) - abs(1.0/y_true))/abs(1.0/y_true))\n",
    "  h2e.Fill(abs(y_true), (abs(1.0/y_meas) - abs(1.0/y_true))/abs(1.0/y_true))\n",
    "\n",
    "\n",
    "c = ROOT.TCanvas()\n",
    "h1.SetMarkerStyle(20)\n",
    "h1.Draw()\n",
    "c.Draw()\n",
    "print h1.GetEntries(), h1.GetMean(), h1.GetRMS()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "c = ROOT.TCanvas()\n",
    "h2a.Draw(\"COLZ\")\n",
    "c.Draw()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "c = ROOT.TCanvas()\n",
    "h2b.Draw(\"COLZ\")\n",
    "c.Draw()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "c = ROOT.TCanvas()\n",
    "h2c.Draw(\"COLZ\")\n",
    "c.Draw()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "c = ROOT.TCanvas()\n",
    "h2d.Draw(\"COLZ\")\n",
    "c.Draw()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": [
    "c = ROOT.TCanvas()\n",
    "h2e.SetStats(0)\n",
    "h2e.SetTitle(\"\")\n",
    "h2e.GetXaxis().SetTitle(\"gen 1/p_{T} [1/GeV]\")\n",
    "h2e.GetYaxis().SetTitle(\"#Delta(p_{T})/p_{T}\")\n",
    "#h2e.GetYaxis().SetRangeUser(-1, 2)\n",
    "h2e.Draw(\"COLZ\")\n",
    "c.Draw()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "c = ROOT.TCanvas()\n",
    "\n",
    "hname = \"h2e\"\n",
    "h = h2e.Clone(\"h2e_clone\")\n",
    "#h.Draw(\"COLZ\")\n",
    "#gPad.Print(hname+\".png\")\n",
    "#h.RebinX(2)\n",
    "\n",
    "#h_pfx = h.ProfileX(hname+\"_pfx\", 1, -1, \"s\")\n",
    "#h_pfx.SetMaximum(1.2)\n",
    "#h_pfx.SetMinimum(-0.2)\n",
    "#h_pfx.Draw()\n",
    "#h_pfx.Fit(\"pol1\", \"\", \"\", 0.025, 0.2499)\n",
    "#gPad.Print(h_pfx.GetName()+\".png\")\n",
    "#\n",
    "\n",
    "if True:\n",
    "  # Apply gaussian fits\n",
    "  gr1 = ROOT.TGraphAsymmErrors(h.GetNbinsX())\n",
    "  gr2 = ROOT.TGraphAsymmErrors(h.GetNbinsX())\n",
    "  gr1_aspt = ROOT.TGraphAsymmErrors(h.GetNbinsX())\n",
    "  gr2_aspt = ROOT.TGraphAsymmErrors(h.GetNbinsX())\n",
    "  for i in xrange(h.GetNbinsX()):\n",
    "    h_py = h.ProjectionY(\"_py\", i+1, i+1)\n",
    "    if h_py.Integral() < 15:  continue\n",
    "    #r = h_py.Fit(\"gaus\", \"SNQ\")\n",
    "    r = h_py.Fit(\"gaus\", \"SNQ\", \"\", h_py.GetMean() - 0.04*8, h_py.GetMean() + 0.04*8)\n",
    "    mean, sigma, meanErr, sigmaErr = r.Parameter(1), r.Parameter(2), r.ParError(1), r.ParError(2)\n",
    "    gr1.SetPoint(i, h.GetXaxis().GetBinCenter(i+1), mean)\n",
    "    gr1.SetPointError(i, 0, 0, sigma, sigma)\n",
    "    gr2.SetPoint(i, h.GetXaxis().GetBinCenter(i+1), sigma)\n",
    "    gr2.SetPointError(i, 0, 0, sigmaErr, sigmaErr)\n",
    "    gr1_aspt.SetPoint(i, 1.0/h.GetXaxis().GetBinCenter(i+1), mean)\n",
    "    gr1_aspt.SetPointError(i, 0, 0, sigma, sigma)\n",
    "    gr2_aspt.SetPoint(i, 1.0/h.GetXaxis().GetBinCenter(i+1), sigma)\n",
    "    gr2_aspt.SetPointError(i, 0, 0, sigmaErr, sigmaErr)\n",
    "  #\n",
    "  hname1 = hname\n",
    "  h_pfx = h.ProfileX(hname1+\"_pfx\", 1, -1, \"s\")\n",
    "  h_pfx.Reset()\n",
    "  h_pfx.SetMaximum(1.2)\n",
    "  h_pfx.SetMinimum(-0.2)\n",
    "  h_pfx.Draw()\n",
    "  gr1.SetMarkerStyle(20)\n",
    "  gr1.Draw(\"p\")\n",
    "  #gr1.Fit(\"pol1\", \"\", \"\", 0.025, 0.2499)\n",
    "  #gPad.Print(h_pfx.GetName()+\".png\")\n",
    "  #\n",
    "  hname2 = hname\n",
    "  h_pfx = h.ProfileX(hname2+\"_pfx\", 1, -1, \"s\")\n",
    "  h_pfx.Reset()\n",
    "  h_pfx.SetMaximum(1)\n",
    "  h_pfx.SetMinimum(0)\n",
    "  h_pfx.Draw()\n",
    "  gr2.SetMarkerStyle(20)\n",
    "  gr2.Draw(\"p\")\n",
    "  #gr2.Fit(\"pol1\", \"\", \"\", 0.025, 0.2499)\n",
    "  #gPad.Print(h_pfx.GetName()+\".png\")\n",
    "  #\n",
    "  hname1 = hname\n",
    "  h_pfx = h.ProfileX(hname1+\"_pfx\", 1, -1, \"s\")\n",
    "  h_pfx.Reset()\n",
    "  h_pfx.SetBins(50, 0, 50)\n",
    "  h_pfx.GetXaxis().SetTitle(\"gen p_{T} [GeV]\")\n",
    "  h_pfx.GetYaxis().SetTitle(\"#Delta(p_{T})/p_{T} bias\")\n",
    "  h_pfx.SetMaximum(1.2)\n",
    "  h_pfx.SetMinimum(-0.2)\n",
    "  h_pfx.Draw()\n",
    "  gr1_aspt.SetMarkerStyle(20)\n",
    "  gr1_aspt.Draw(\"p\")\n",
    "  #gr1_aspt.Fit(\"pol1\", \"\", \"\", 0.025, 0.2499)\n",
    "  #ROOT.gPad.SetLogx(1)\n",
    "  #ROOT.gPad.Print(h_pfx.GetName()+\".png\")\n",
    "  #ROOT.gPad.SetLogx(0)\n",
    "  #\n",
    "  hname2 = hname\n",
    "  h_pfx = h.ProfileX(hname2+\"_pfx\", 1, -1, \"s\")\n",
    "  h_pfx.Reset()\n",
    "  h_pfx.SetStats(0)\n",
    "  h_pfx.SetBins(50, 0, 50)\n",
    "  h_pfx.GetXaxis().SetTitle(\"gen p_{T} [GeV]\")\n",
    "  h_pfx.GetYaxis().SetTitle(\"#Delta(p_{T})/p_{T} resolution\")\n",
    "  h_pfx.SetMaximum(1.2)\n",
    "  h_pfx.SetMinimum(-0.2)\n",
    "  #h_pfx.SetMaximum(0.1)\n",
    "  #h_pfx.SetMinimum(-0.01)\n",
    "  h_pfx.Draw()\n",
    "  gr2_aspt.SetMarkerStyle(20)\n",
    "  gr2_aspt.Draw(\"p\")\n",
    "  #gr2_aspt.Fit(\"pol1\", \"\", \"\", 0.025, 0.2499)\n",
    "  #ROOT.gPad.SetLogx(1)\n",
    "  #ROOT.gPad.Print(h_pfx.GetName()+\".png\")\n",
    "  #ROOT.gPad.SetLogx(0)\n",
    "    \n",
    "c.Draw()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# For classification\n",
    "hh1a = ROOT.TH1F(\"hh1a\", \"hh1a\", 120, -0.1, 1.1)\n",
    "hh1b = ROOT.TH1F(\"hh1b\", \"hh1b\", 120, -0.1, 1.1)\n",
    "\n",
    "for i in xrange(nentries_test):\n",
    "  if y_test[1][i] != 100.:  # mask_value is set to 100\n",
    "    hh1a.Fill(y_test_meas[1][i])\n",
    "\n",
    "for i in xrange(y_adv_test[1].shape[0]):\n",
    "  hh1b.Fill(y_adv_test_meas[1][i])\n",
    "\n",
    "\n",
    "c = ROOT.TCanvas()\n",
    "hh1a.SetLineColor(632)  # kRed\n",
    "hh1a.Scale(1.0/hh1a.Integral())\n",
    "hh1a.Draw(\"hist\")\n",
    "hh1b.SetLineColor(1)  # kBlack\n",
    "hh1b.Scale(1.0/hh1b.Integral())\n",
    "hh1b.Draw(\"same hist\")\n",
    "c.Draw()\n",
    "c.SetLogy()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "try:\n",
    "  y_true = np.concatenate((y_test[1][:nentries_test], y_adv_test[1]))\n",
    "except ValueError:\n",
    "  y_true = np.concatenate((y_test[1][:nentries_test, np.newaxis], y_adv_test[1]))\n",
    "y_pred = np.concatenate((y_test_meas[1], y_adv_test_meas[1]))\n",
    "y_pred_0 = np.concatenate((y_test_meas[0], y_adv_test_meas[0]))\n",
    "\n",
    "mask = (y_true != 100.)  # mask_value is set to 100\n",
    "y_true = y_true[mask]\n",
    "y_pred = y_pred[mask]\n",
    "y_pred_0 = y_pred_0[mask]\n",
    "\n",
    "mask = np.abs(1.0/y_pred_0) > discr_pt_cut\n",
    "y_true = y_true[mask]\n",
    "y_pred = y_pred[mask]\n",
    "y_pred_0 = y_pred_0[mask]\n",
    "\n",
    "\n",
    "fpr, tpr, thresh = roc_curve(y_true, y_pred)\n",
    "\n",
    "fig, ax = plt.subplots(tight_layout=True)\n",
    "ax.plot(fpr, tpr)\n",
    "ax.set_xlabel('False positive rate')\n",
    "ax.set_ylabel('True positive rate')\n",
    "ax.set_title('ROC curve')\n",
    "ax.set_xlim([0.0,1.0])\n",
    "ax.set_ylim([0.9,1.0])\n",
    "\n",
    "idx = np.searchsorted(tpr, [0.9, 0.925, 0.95, 0.97, 0.98, 0.985, 0.99, 0.995])\n",
    "print tpr[idx]\n",
    "print fpr[idx]\n",
    "print thresh[idx]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Build trigger ####\n",
    "\n",
    "pt_bins = (-0.50, -0.333333, -0.25, -0.20, -0.15, -0.10, -0.05, 0.05, 0.10, 0.15, 0.20, 0.25, 0.333333, 0.50)\n",
    "def find_pt_bin(pt):\n",
    "  ipt = np.digitize((pt,), pt_bins[1:])[0]  # skip lowest edge\n",
    "  ipt = np.clip(ipt, 0, len(pt_bins)-2)\n",
    "  return ipt\n",
    "def emtf_road_quality(ipt):\n",
    "  best_ipt = find_pt_bin(0.)\n",
    "  return best_ipt - abs(ipt - best_ipt)\n",
    "\n",
    "class MyTriggerV1(object):\n",
    "  \n",
    "  def __init__(self):\n",
    "    pass\n",
    "\n",
    "  def get_trigger_pt(self, y_meas):\n",
    "    pt = np.abs(1.0/y_meas)\n",
    "    pt_clipped = np.clip(pt, 3., 60.)\n",
    "    pt = pt * (1.0 + (0.08813 + 0.009504 * pt_clipped) * 1.28155)  # erf(1.28155/sqrt(2)) = 0.8 [90% upper limit from -1 to -1]\n",
    "    return pt\n",
    "  \n",
    "  def pass_trigger(self, x, ndof, y_meas, y_discr):\n",
    "    trk_mode = 0\n",
    "    x_mode_vars = np.equal(x[nlayers*5+3:nlayers*5+8], 1)\n",
    "    for i, x_mode_var in enumerate(x_mode_vars):\n",
    "      if i == 0:\n",
    "        station = 1\n",
    "      else:\n",
    "        station = i\n",
    "      if x_mode_var:\n",
    "        trk_mode |= (1 << (4 - station))\n",
    "\n",
    "    ipt1 = (x[nlayers*5+0:nlayers*5+1] * 6 + 6).astype(np.int32)\n",
    "    ipt2 = find_pt_bin(y_meas)\n",
    "    quality1 = emtf_road_quality(ipt1)\n",
    "    quality2 = emtf_road_quality(ipt2)\n",
    "    \n",
    "    if trk_mode in (11,13,14,15) and quality2 <= (quality1+1):\n",
    "      if np.abs(1.0/y_meas) > discr_pt_cut:\n",
    "        if ndof <= 3:\n",
    "          #trigger = (y_discr > 0.5)\n",
    "          trigger = (y_discr > 0.8)\n",
    "          #trigger = (y_discr > 0.95)\n",
    "        else:\n",
    "          trigger = (y_discr > 0.5393)\n",
    "          #trigger = (y_discr > 0.95)\n",
    "      else:\n",
    "        trigger = True\n",
    "    else:\n",
    "      trigger = False\n",
    "    return trigger\n",
    "\n",
    "\n",
    "class MyTriggerV2(object):\n",
    "  \n",
    "  def __init__(self):\n",
    "    pass\n",
    "\n",
    "  def get_trigger_pt(self, x, y_meas):\n",
    "    zone = int(x[(nlayers*5) + 1] * 5)\n",
    "    \n",
    "    pt = np.abs(1.0/y_meas)\n",
    "    pt_clipped = np.clip(pt, 3., 60.)\n",
    "    #pt = pt * (1.0 + (0.081 + 0.009 * pt_clipped) * 1.28155)  # erf(1.28155/sqrt(2)) = 0.8 [90% upper limit from -1 to -1]\n",
    "    #pt = pt * (1.0 + (0.080 + 0.0051 * pt_clipped) * 1.28155)  # erf(1.28155/sqrt(2)) = 0.8 [90% upper limit from -1 to -1]\n",
    "    #pt = pt * (1.0 + (0.18643468 + 0.00983759 * pt_clipped))\n",
    "    #pt = pt * (1.0 + (0.19061872 + 0.00897454 * pt_clipped))\n",
    "    #pt = pt * (1.0 + (0.21251148 + 0.00658309 * 0.97 * pt_clipped))\n",
    "    #pt = pt * (1.0 + (0.21540622 + 0.00588042 * 0.97 * pt_clipped))\n",
    "    #pt = pt * (1.0 + (0.23736955 + 0.00444597 * pt_clipped))\n",
    "    \n",
    "    sf =[[  0.00000000e+00,   2.49868810e-01,   9.67491604e-03],\n",
    "         [  1.00000000e+00,   2.02819258e-01,   3.44642927e-03],\n",
    "         [  2.00000000e+00,   1.34788156e-01,   3.97331361e-03],\n",
    "         [  3.00000000e+00,   1.34788156e-01,   3.97331361e-03],\n",
    "         [  4.00000000e+00,   2.05471098e-01,   7.20871985e-03],\n",
    "         [  5.00000000e+00,   2.05471098e-01,   7.20871985e-03]]\n",
    "    \n",
    "    sf =[[  0.00000000e+00,   2.63994873e-01,   9.85030923e-03],\n",
    "         [  1.00000000e+00,   1.79664418e-01,   5.61202876e-03],\n",
    "         [  2.00000000e+00,   1.62771225e-01,   2.96276459e-03],\n",
    "         [  3.00000000e+00,   1.62771225e-01,   2.96276459e-03],\n",
    "         [  4.00000000e+00,   1.40744388e-01,   6.65116590e-03],\n",
    "         [  5.00000000e+00,   1.40744388e-01,   6.65116590e-03]] \n",
    "\n",
    "    a, b = sf[zone][1], sf[zone][2]\n",
    "    pt = pt * (1.0 + (a + b * pt_clipped))\n",
    "    return pt\n",
    "  \n",
    "  def pass_trigger(self, x, ndof, y_meas, y_discr):\n",
    "    trk_mode = 0\n",
    "    x_mode_vars = np.equal(x[nlayers*5+3:nlayers*5+8], 1)\n",
    "    for i, x_mode_var in enumerate(x_mode_vars):\n",
    "      if i == 0:\n",
    "        station = 1\n",
    "      else:\n",
    "        station = i\n",
    "      if x_mode_var:\n",
    "        trk_mode |= (1 << (4 - station))\n",
    "\n",
    "    straightness = int(x[(nlayers*5) + 0] * 6) + 6\n",
    "    \n",
    "    ipt1 = straightness\n",
    "    ipt2 = find_pt_bin(y_meas)\n",
    "    quality1 = emtf_road_quality(ipt1)\n",
    "    quality2 = emtf_road_quality(ipt2)\n",
    "    \n",
    "    if trk_mode in (11,13,14,15) and quality2 <= (quality1+1):\n",
    "      if np.abs(1.0/y_meas) > discr_pt_cut:\n",
    "        if ndof <= 3:\n",
    "          #trigger = (y_discr > 0.8)\n",
    "          trigger = (y_discr > 0.996)\n",
    "        else:\n",
    "          #trigger = (y_discr > 0.5393)\n",
    "          trigger = (y_discr > 0.992)\n",
    "      else:\n",
    "        trigger = (y_discr >= 0.)  # True\n",
    "    else:\n",
    "      trigger = (y_discr < 0.)  # False\n",
    "    return trigger\n",
    "\n",
    "# ______________________________________________________________________________\n",
    "mytrigger = MyTriggerV2()\n",
    "\n",
    "from rootpy.plotting import Hist, Efficiency\n",
    "from math import sqrt\n",
    "histograms = {}\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Make trigger efficiency ####\n",
    "\n",
    "eff_pt_bins = (0., 0.5, 1., 2., 3., 4., 5., 6., 8., 10., 12., 14., 16., 18., 20., 22., 24., 26., 28., 30., 35., 40., 45., 50., 60., 80., 120.)\n",
    "\n",
    "hname = \"x_eff_vs_genpt_denom\"\n",
    "h1c_denom = Hist(eff_pt_bins, name=hname, title=\"; gen p_{T} [GeV]\", type='F')\n",
    "hname = \"x_eff_vs_genpt_l1pt10\"\n",
    "h1c_numer_1 = Hist(eff_pt_bins, name=hname, title=\"; gen p_{T} [GeV]\", type='F')\n",
    "hname = \"x_eff_vs_genpt_l1pt20\"\n",
    "h1c_numer_2 = Hist(eff_pt_bins, name=hname, title=\"; gen p_{T} [GeV]\", type='F')\n",
    "hname = \"x_eff_vs_genpt_l1pt30\"\n",
    "h1c_numer_3 = Hist(eff_pt_bins, name=hname, title=\"; gen p_{T} [GeV]\", type='F')\n",
    "hname = \"x_eff_vs_genpt_l1pt40\"\n",
    "h1c_numer_4 = Hist(eff_pt_bins, name=hname, title=\"; gen p_{T} [GeV]\", type='F')\n",
    "hname = \"x_eff_vs_genpt_l1pt50\"\n",
    "h1c_numer_5 = Hist(eff_pt_bins, name=hname, title=\"; gen p_{T} [GeV]\", type='F')\n",
    "\n",
    "h1c_data = []\n",
    "\n",
    "# Loop over events\n",
    "for x, ndof, y_meas, y_discr, y_true in zip(x_test, x_test, y_test_meas[0], y_test_meas[1], y_test[0]):\n",
    "\n",
    "  ndof = 4  #FIXME\n",
    "  \n",
    "  zone = int(x[(nlayers*5) + 1] * 5)\n",
    "  \n",
    "  trigger = mytrigger.pass_trigger(x, ndof, y_meas, y_discr)\n",
    "  \n",
    "  #pt = mytrigger.get_trigger_pt(y_meas)\n",
    "  pt = mytrigger.get_trigger_pt(x, y_meas)\n",
    "  pt_true = np.abs(1.0/y_true)\n",
    "  \n",
    "  h1c_denom.fill(pt_true)\n",
    "  if trigger and (pt > 10.):\n",
    "    h1c_numer_1.fill(pt_true)\n",
    "  if trigger and (pt > 20.):\n",
    "    h1c_numer_2.fill(pt_true)\n",
    "  if trigger and (pt > 30.):\n",
    "    h1c_numer_3.fill(pt_true)\n",
    "  if trigger and (pt > 40.):\n",
    "    h1c_numer_4.fill(pt_true)\n",
    "  if trigger and (pt > 50.):\n",
    "    h1c_numer_5.fill(pt_true)\n",
    "    \n",
    "  if trigger:\n",
    "    h1c_data.append((zone, np.asscalar(np.abs(1.0/y_true)), np.asscalar(np.abs(1.0/y_meas))))\n",
    "\n",
    "h1c_eff = Efficiency(h1c_numer_2, h1c_denom)\n",
    "h1c_eff.SetStatisticOption(0)  # kFCP\n",
    "h1c_eff.SetConfidenceLevel(0.682689492137)  # one sigma\n",
    "h1c_eff.SetMarkerStyle(1)\n",
    "h1c_eff.SetMarkerColor(800)  # kOrange\n",
    "h1c_eff.SetLineColor(800)  # kOrange\n",
    "h1c_eff.SetLineWidth(2)\n",
    "h1c_eff.SetDirectory(0)\n",
    "histograms['h1c_numer_1'] = h1c_numer_1\n",
    "histograms['h1c_numer_2'] = h1c_numer_2\n",
    "histograms['h1c_numer_3'] = h1c_numer_3\n",
    "histograms['h1c_numer_4'] = h1c_numer_4\n",
    "histograms['h1c_numer_5'] = h1c_numer_5\n",
    "histograms['h1c_denom'] = h1c_denom\n",
    "histograms['h1c_eff'] = h1c_eff\n",
    "\n",
    "for xx, pt in [(h1c_numer_1, 10.), (h1c_numer_2, 20.), (h1c_numer_3, 30.), (h1c_numer_4, 40.), (h1c_numer_5, 50.)]:\n",
    "  b = xx.FindBin(pt+0.5)\n",
    "  print pt, xx.GetBinContent(b)/h1c_denom.GetBinContent(b)\n",
    "\n",
    "# Add corrections\n",
    "if False:\n",
    "  nbinsx = h1c_eff.GetTotalHistogram().GetNbinsX()\n",
    "  corrections = [0.0, 0.0, 0.0, 2.5596844660416443e-05, 9.071900979369844e-05, -0.00025407866698875234, 3.9318943372533294e-05, 0.00046750609322471475, -0.0012868531325132167, -0.0017629378199139414, -0.003412967281340079, -1.859263302672609e-05, -0.0027697063960877566, -0.011912089953303617, -0.012565904385017701, -0.01502952024543791, -0.007091832957321742, -0.011625792518549893, -0.017156862745097978, -0.007722007722007707, -0.008966446308134701, -0.00857140366324638, -0.021269462895507463, -0.009598486441034226, -0.01485925792486198, -0.010991760558270336]\n",
    "  assert(len(corrections) == nbinsx)\n",
    "  for b in xrange(1,nbinsx+1):\n",
    "    old_eff = h1c_eff.GetEfficiency(b)\n",
    "    new_eff = old_eff + corrections[b-1]\n",
    "    h1c_eff.GetPassedHistogram().SetBinContent(b, h1c_eff.GetTotalHistogram().GetBinContent(b) * new_eff)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "infile1 = ROOT.TFile.Open(\"emtf_eff_vs_genpt_l1pt20.root\")\n",
    "frame = infile1.Get(\"emtf_eff_vs_genpt_l1pt20_denom_clone\")\n",
    "h1a_eff = infile1.Get(\"emtf_eff_vs_genpt_l1pt20_denom_clone\")\n",
    "h1b_eff = infile1.Get(\"emtf2023_eff_vs_genpt_l1pt20_denom_clone\")\n",
    "\n",
    "c = ROOT.TCanvas()\n",
    "frame.Draw()\n",
    "h1a_eff.Draw(\"same\")\n",
    "h1b_eff.Draw(\"same\")\n",
    "h1c_eff.Draw(\"same\")\n",
    "c.Draw()\n",
    "\n",
    "# Find corrections\n",
    "if False:\n",
    "  nbinsx = h1c_eff.GetTotalHistogram().GetNbinsX()\n",
    "  corrections = []\n",
    "  for b in xrange(1,nbinsx+1):\n",
    "    eff1 = h1b_eff.GetEfficiency(b)\n",
    "    eff2 = h1c_eff.GetEfficiency(b)\n",
    "    corr = eff1 - eff2\n",
    "    corrections.append(corr)\n",
    "  print corrections"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Find pT scale factor\n",
    "\n",
    "if True:\n",
    "  from sklearn import linear_model\n",
    "  \n",
    "  h1c_data = np.asarray(h1c_data)\n",
    "  \n",
    "  h1c_data_zone = h1c_data[:,0].astype(np.int32)\n",
    "  \n",
    "  fig, axs = plt.subplots(2, 3, figsize=(4*3,4*2), tight_layout=True)\n",
    "  myscales = []\n",
    "  \n",
    "  for zone in xrange(6):  # 6 zones\n",
    "    h1c_data_sf = []\n",
    "\n",
    "    #for pt in np.linspace(12, 32, 6):  # 4 GeV bin size\n",
    "    for pt in np.linspace(14, 30, 5):  # 4 GeV bin size\n",
    "      if zone == 4 or zone == 5:\n",
    "        sel = ((h1c_data_zone == 4) | (h1c_data_zone == 5))  & ((pt-2) <= h1c_data[:, 1]) & (h1c_data[:, 1] < (pt+2))\n",
    "      elif zone == 2 or zone == 3:\n",
    "        sel = ((h1c_data_zone == 2) | (h1c_data_zone == 3))  & ((pt-2) <= h1c_data[:, 1]) & (h1c_data[:, 1] < (pt+2))\n",
    "      else:\n",
    "        sel = (h1c_data_zone == zone) & ((pt-2) <= h1c_data[:, 1]) & (h1c_data[:, 1] < (pt+2))\n",
    "      #sel = ((pt-2) < h1c_data[:, 1]) & (h1c_data[:, 1] < (pt+2))\n",
    "      data = h1c_data[sel]\n",
    "      data = data[:,1] / data[:,2]  # pt_true/pt_xml\n",
    "      sf = np.percentile(data, [90.5], overwrite_input=True)\n",
    "      h1c_data_sf.append((pt, np.asscalar(sf)))\n",
    "    \n",
    "    # Fit\n",
    "    h1c_data_sf = np.asarray(h1c_data_sf)\n",
    "    h1c_x = h1c_data_sf[:,0][:, np.newaxis]\n",
    "    h1c_y = h1c_data_sf[:,1] - 1.0\n",
    "    linreg = linear_model.LinearRegression()\n",
    "    linreg.fit(h1c_x, h1c_y)\n",
    "    myscales.append((zone, linreg.intercept_, linreg.coef_[0]))\n",
    "    _ = axs[(zone/3, zone%3)].scatter(h1c_x, h1c_y)\n",
    "    _ = axs[(zone/3, zone%3)].plot(h1c_x, linreg.predict(h1c_x))\n",
    "\n",
    "  print np.array2string(np.array(myscales, dtype=np.float32), separator=', ')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Make trigger rates ####\n",
    "\n",
    "hname = \"highest_x_absEtaMin0_absEtaMax2.5_qmin12_pt\"\n",
    "rates_hist = Hist(100, 0., 100., name=hname, title=\"; p_{T} [GeV]; entries\", type='F')\n",
    "\n",
    "rates_nevents = 2000\n",
    "rates_njobs = 100\n",
    "rates_array = np.zeros((rates_njobs,rates_nevents), dtype=np.float32)\n",
    "\n",
    "for x, ndof, y_meas, y_discr, aux in zip(x_adv_test, x_adv_test, y_adv_test_meas[0], y_adv_test_meas[1], aux_adv_test):\n",
    "  \n",
    "  ndof = 4  #FIXME\n",
    "  \n",
    "  (jobid, ievt, highest_part_pt, highest_track_pt) = aux\n",
    "  jobid = int(jobid)\n",
    "  ievt = int(ievt)\n",
    "  \n",
    "  #pt = mytrigger.get_trigger_pt(y_meas)\n",
    "  pt = mytrigger.get_trigger_pt(x, y_meas)\n",
    "  \n",
    "  trigger = mytrigger.pass_trigger(x, ndof, y_meas, y_discr)\n",
    "\n",
    "  if trigger:\n",
    "    rates_array[jobid,ievt] = max(rates_array[jobid,ievt], pt)\n",
    "\n",
    "rates_nevents_1 = 0\n",
    "\n",
    "for jobid in xrange(rates_array.shape[0]):\n",
    "  if rates_array[jobid].sum() > 0.:\n",
    "    for ievt in xrange(rates_array.shape[1]):\n",
    "      x = rates_array[jobid,ievt]\n",
    "      if x > 0.:\n",
    "        highest_pt = min(100.-1e-3, x)\n",
    "        rates_hist.fill(highest_pt)\n",
    "    rates_nevents_1 += rates_nevents\n",
    "\n",
    "print rates_nevents * rates_njobs, rates_nevents_1\n",
    "\n",
    "\n",
    "def make_ptcut(h):\n",
    "  use_overflow = True\n",
    "  binsum = 0\n",
    "  binerr2 = 0\n",
    "  for ib in xrange(h.GetNbinsX()+2-1, 0-1, -1):\n",
    "    if (not use_overflow) and (ib == 0 or ib == h.GetNbinsX()+1):\n",
    "      continue\n",
    "    binsum += h.GetBinContent(ib)\n",
    "    binerr2 += h.GetBinError(ib)**2\n",
    "    h.SetBinContent(ib, binsum)\n",
    "    h.SetBinError(ib, sqrt(binerr2))\n",
    "  return\n",
    "\n",
    "def make_rate(h, nevents):\n",
    "  orbitFreq = 11245.6\n",
    "  nCollBunches = 1866\n",
    "  nZeroBiasEvents = nevents\n",
    "  convFactorToHz = orbitFreq * nCollBunches / nZeroBiasEvents\n",
    "  h.Scale(convFactorToHz / 1000.)\n",
    "  return\n",
    "\n",
    "make_ptcut(rates_hist)\n",
    "make_rate(rates_hist, rates_nevents_1)\n",
    "\n",
    "rates_hist.SetLineColor(800)  # kOrange\n",
    "rates_hist.SetLineWidth(2)\n",
    "rates_hist.SetDirectory(0)\n",
    "histograms['rates_hist'] = rates_hist"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "c = ROOT.TCanvas()\n",
    "rates_hist.Draw(\"hist\")\n",
    "c.SetLogy()\n",
    "c.Draw()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Rates ####\n",
    "\n",
    "infile2 = ROOT.TFile.Open(\"emtf2023_rate_reduction.root\")\n",
    "#cc1 = infile2.Get(\"cc1\")\n",
    "denom = infile2.Get(\"denom\")\n",
    "numer = infile2.Get(\"numer\")\n",
    "ratio = infile2.Get(\"ratio\")\n",
    "\n",
    "rates_hist_ratio = rates_hist.Clone(\"ratio2\")\n",
    "rates_hist_ratio.Divide(rates_hist_ratio, denom, 1, 1, \"\")\n",
    "\n",
    "cc1 = ROOT.TCanvas(\"cc1\", \"cc1\", 600, 700)\n",
    "cc1.Divide(1,2)\n",
    "cc1_1 = cc1.GetPad(1)\n",
    "cc1_1.SetPad(0.01,0.25,0.99,0.99)\n",
    "cc1_1.SetBottomMargin(0.01)\n",
    "cc1_1.SetGrid()\n",
    "cc1_1.SetLogy()\n",
    "cc1_2 = cc1.GetPad(2)\n",
    "cc1_2.SetPad(0.01,0.01,0.99,0.25)\n",
    "cc1_2.SetTopMargin(0.01)\n",
    "cc1_2.SetBottomMargin(0.43)\n",
    "cc1_2.SetGrid()\n",
    "\n",
    "cc1_1.cd()\n",
    "denom.Draw(\"hist\")\n",
    "numer.Draw(\"hist same\")\n",
    "rates_hist.Draw(\"hist same\")\n",
    "cc1_2.cd()\n",
    "ratio.Draw(\"hist same\")\n",
    "rates_hist_ratio.Draw(\"hist same\")\n",
    "cc1.Draw()\n",
    "\n",
    "print denom.GetBinContent(denom.FindBin(20.)), numer.GetBinContent(numer.FindBin(20.)), rates_hist.GetBinContent(rates_hist.FindBin(20.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# from https://github.com/keras-team/keras/issues/4843\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from keras.datasets import mnist\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.metrics import categorical_accuracy\n",
    "from keras.initializers import glorot_uniform, zero\n",
    "\n",
    "\n",
    "input_dim = 28*28\n",
    "output_dim = 10\n",
    "x = K.placeholder(name=\"x\", shape=(None, input_dim))\n",
    "ytrue = K.placeholder(name=\"y\", shape=(None, output_dim))\n",
    "\n",
    "hidden_dim = 128\n",
    "W1 = K.variable(glorot_uniform()([input_dim, hidden_dim]))\n",
    "b1 = K.variable(zero()((hidden_dim,)))\n",
    "W2 = K.variable(glorot_uniform()([hidden_dim, output_dim]))\n",
    "b2 = K.variable(zero()((output_dim,)))\n",
    "params = [W1, b1, W2, b2]\n",
    "\n",
    "\n",
    "hidden = K.sigmoid(K.dot(x, W1)+b1)\n",
    "ypred = K.softmax(K.dot(hidden, W2)+b2)\n",
    "\n",
    "\n",
    "loss = K.mean(K.categorical_crossentropy(ytrue, ypred),axis=None)\n",
    "\n",
    "accuracy = categorical_accuracy(ytrue, ypred)\n",
    "\n",
    "opt = Adam()\n",
    "updates = opt.get_updates(params, [], loss, )\n",
    "train = K.function([x, ytrue],[loss, accuracy],updates=updates)\n",
    "\n",
    "test = K.function([x, ytrue], [loss, accuracy])\n",
    "\n",
    "((xtrain, ytrain),(xtest, ytest)) = mnist.load_data()\n",
    "(xtrain, xtest) = [x.reshape((-1, input_dim))/255.0 for x in (xtrain, xtest)]\n",
    "(ytrain, ytest) = [to_categorical(y, output_dim) for y in (ytrain, ytest)]\n",
    "for epoch in range(1000):\n",
    "\tloss, accuracy = train([xtrain, ytrain])\n",
    "\ttest_loss, test_accuracy = test([xtest, ytest])\n",
    "\tprint(\"Epoch: {}, Train Loss: {}, Train Accuracy: {}, Test Loss: {}, Test Accuracy: {}\".format(\n",
    "\t\tepoch, loss, accuracy, test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "  print x_train.shape, y_train[0].shape, x_mask_train.shape\n",
    "  print np.mean(y_train[0]), np.std(y_train[0]), np.percentile(y_train[0], [2,98])\n",
    "  \n",
    "  fig, axs = plt.subplots(72/4, 4, figsize=(4*4,4*72/4), tight_layout=True)\n",
    "\n",
    "  for i in xrange(x_train.shape[1]):\n",
    "    lay = (i % nlayers)\n",
    "    mask = x_mask_train[...,lay].copy()\n",
    "    if i >= (nlayers*5):\n",
    "      mask *= False\n",
    "    \n",
    "    valid = ~mask\n",
    "    x_i = x_train[valid,i]\n",
    "    y_i = y_train[0][valid,0]\n",
    "\n",
    "    ymin, ymax = -0.6, 0.6\n",
    "    if i < (nlayers*3):\n",
    "      xmin, xmax = -1.5, 1.5\n",
    "    elif i < (nlayers*5):\n",
    "      xmin, xmax = -1.5, 1.5\n",
    "    elif i < 68:\n",
    "      xmin, xmax = -1.5, 1.5\n",
    "    \n",
    "    hist = axs[(i/4, i%4)].hist2d(x_i, y_i, bins=40, range=[[xmin, xmax], [ymin, ymax]], cmap=plt.cm.viridis)  #norm=colors.LogNorm(),\n",
    "    if x_i.size > 0:\n",
    "      print i, np.mean(x_i), np.std(x_i), np.percentile(x_i, [2,98])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "  from sklearn.linear_model import LinearRegression\n",
    "  from sklearn.covariance import EmpiricalCovariance, MinCovDet\n",
    "\n",
    "  #print x_train.shape, y_train[0].shape, x_mask_train.shape\n",
    "\n",
    "  #fig, axs = plt.subplots(72/4, 4, figsize=(4*4,4*72/4), tight_layout=True)\n",
    "  \n",
    "  coefs = np.ones((nlayers * 6) + 4)\n",
    "\n",
    "  for i in xrange(x_train.shape[1]):\n",
    "    lay = (i % nlayers)\n",
    "    mask = x_mask_train[...,lay].copy()\n",
    "    if i >= (nlayers*5):\n",
    "      mask *= False\n",
    "    \n",
    "    valid = ~mask\n",
    "    valid = valid & (np.abs(1.0/y_train[0]) < 14.)  # skip high pT part\n",
    "    x_i = x_train[valid,i].copy()\n",
    "    y_i = y_train[0][valid].copy()\n",
    "    \n",
    "    nentries_test = 100000\n",
    "    x_i = x_i[:nentries_test]\n",
    "    y_i = y_i[:nentries_test]\n",
    "    y_i /= (1.0/np.sqrt(12))  # (b-a)/sqrt(12)\n",
    "    \n",
    "    if x_i.size > 0 and np.std(x_i) > 0.:\n",
    "      coef = 1.0\n",
    "      \n",
    "      # x_phi\n",
    "      if (i < nlayers):\n",
    "        mcd = MinCovDet(assume_centered=True).fit(np.column_stack((x_i,y_i)))\n",
    "        coef = mcd.covariance_[0,1] / mcd.covariance_[0,0]  # Cov[x,y]/Var[x]\n",
    "        print i, coef, np.std(x_i), np.std(x_i * coef), np.std(y_i)\n",
    "        \n",
    "        #lr = LinearRegression(fit_intercept=False).fit(x_i[:,np.newaxis], y_i)\n",
    "        #coef = lr.coef_[0]\n",
    "        #print i, coef, np.std(x_i), np.std(x_i * coef), np.std(y_i)\n",
    "      \n",
    "      # x_theta\n",
    "      elif (nlayers) <= i < (nlayers*2):\n",
    "        if lay == 0 or lay == 1:  # ME1/1 or ME1/2\n",
    "          mcd = MinCovDet(assume_centered=True).fit(np.column_stack((np.abs(x_i),np.abs(y_i))))\n",
    "          coef = mcd.covariance_[0,1] / mcd.covariance_[0,0]  # Cov[x,y]/Var[x]\n",
    "        else:\n",
    "          coef = 1.0/np.std(x_i)\n",
    "        print i, coef, np.std(x_i), np.std(x_i * coef), np.std(y_i)\n",
    "      \n",
    "      # x_bend\n",
    "      elif (nlayers*2) <= i < (nlayers*3):\n",
    "        if lay == 0 or lay == 1:  # ME1/1 or ME1/2\n",
    "          mcd = MinCovDet(assume_centered=True).fit(np.column_stack((x_i,y_i)))\n",
    "          coef = mcd.covariance_[0,1] / mcd.covariance_[0,0]  # Cov[x,y]/Var[x]\n",
    "        else:\n",
    "          coef = 1.0/np.std(x_i)\n",
    "        print i, coef, np.std(x_i), np.std(x_i * coef), np.std(y_i)\n",
    "      \n",
    "      coefs[i] = coef  \n",
    "\n",
    "  print np.array2string(coefs, separator=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "  def huber_loss(y_true, y_pred, delta=1.345):\n",
    "    x = K.abs(y_true - y_pred)\n",
    "    squared_loss = 0.5*K.square(x)\n",
    "    absolute_loss = delta * (x - 0.5*delta)\n",
    "    #xx = K.switch(x < delta, squared_loss, absolute_loss)\n",
    "    xx = tf.where(x < delta, squared_loss, absolute_loss)  # needed for tensorflow\n",
    "    #return K.mean(xx, axis=-1)\n",
    "    return xx\n",
    "\n",
    "\n",
    "  a = y_test[0][:nentries_test].copy()\n",
    "  b = y_test_meas[0].copy()\n",
    "\n",
    "  tmp = np.abs(1.0/a) > 20.\n",
    "  a = a[tmp]\n",
    "  b = b[tmp]\n",
    "\n",
    "  #reg_pt_scale = 14.\n",
    "  #a *= reg_pt_scale\n",
    "  #b *= reg_pt_scale\n",
    "\n",
    "  c = huber_loss(a, b)\n",
    "  sess = tf.InteractiveSession()\n",
    "  d = c.eval()\n",
    "  #sess.close()\n",
    "  e = (a-b).reshape(-1)\n",
    "  f = d.reshape(-1)\n",
    "\n",
    "  print len(a), len(b), a, b\n",
    "  print e, f\n",
    "  print np.min(f), np.max(f), np.median(f)\n",
    "  print 0.5 * np.square(e), 1.345 * e\n",
    "  print len(e), np.equal(0.5 * np.square(e), f).sum()\n",
    "  print np.std(e), np.median(np.abs(e))\n",
    "  \n",
    "  fig, ax = plt.subplots()\n",
    "  ax.set_yscale('log')\n",
    "  _ = ax.hist(e, bins=50, range=[-10,10])\n",
    "\n",
    "  #fig, ax = plt.subplots()\n",
    "  #ax.set_yscale('log')\n",
    "  #_ = ax.hist(0.5 * np.square(e), bins=50, range=[0,10])\n",
    "\n",
    "  fig, ax = plt.subplots()\n",
    "  ax.set_yscale('log')\n",
    "  _ = ax.hist(f, bins=50, range=[0,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "  a = y_test[0][:nentries_test].copy()\n",
    "  b = y_test_meas[0].copy()\n",
    "\n",
    "  tmp = np.abs(1.0/a) > 20.\n",
    "  a = a[tmp]\n",
    "  b = b[tmp]\n",
    "\n",
    "  reg_pt_scale = 14.\n",
    "  a *= reg_pt_scale\n",
    "  b *= reg_pt_scale\n",
    "\n",
    "  c = huber_loss(a, b)\n",
    "  sess = tf.InteractiveSession()\n",
    "  d = c.eval()\n",
    "  #sess.close()\n",
    "  e = (a-b).reshape(-1)\n",
    "  f = d.reshape(-1)\n",
    "\n",
    "  print len(a), len(b), a, b\n",
    "  print e, f\n",
    "  print np.min(f), np.max(f), np.median(f)\n",
    "\n",
    "  fig, ax = plt.subplots()\n",
    "  ax.set_yscale('log')\n",
    "  _ = ax.hist(e, bins=50, range=[-10,10])\n",
    "\n",
    "  #fig, ax = plt.subplots()\n",
    "  #ax.set_yscale('log')\n",
    "  #_ = ax.hist(0.5 * np.square(e), bins=50, range=[0,10])\n",
    "\n",
    "  fig, ax = plt.subplots()\n",
    "  ax.set_yscale('log')\n",
    "  _ = ax.hist(f, bins=50, range=[0,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "  def binary_crossentropy(y_true, y_pred, from_logits=False):\n",
    "    target, output = tf.convert_to_tensor(y_true, np.float32), tf.convert_to_tensor(y_pred, np.float32)\n",
    "\n",
    "    # transform back to logits\n",
    "    if not from_logits:\n",
    "      output = K.clip(output, K.epsilon(), 1 - K.epsilon())\n",
    "      output = K.log(output / (1 - output))\n",
    "\n",
    "    xx =  tf.nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n",
    "    #xx =  tf.nn.weighted_cross_entropy_with_logits(targets=target, logits=output, pos_weight=0.5)  # pos_weight < 1 decreases the false positive count\n",
    "    #return K.mean(xx, axis=-1)\n",
    "    return xx\n",
    "\n",
    "\n",
    "  a1 = y_test[1][:nentries_test].copy()\n",
    "  a2 = y_adv_test[1].copy()\n",
    "\n",
    "  b1 = y_test_meas[1].copy()\n",
    "  b2 = y_adv_test_meas[1].copy()\n",
    "\n",
    "  tmp = (a1 != 100.)\n",
    "  a1 = a1[tmp]\n",
    "  b1 = b1[tmp]\n",
    "\n",
    "  a2 = a2[:,0]\n",
    "  b2 = b2[:,0]\n",
    "  tmp = np.random.randint(0, len(a2), len(a1))\n",
    "  a2 = a2[tmp]\n",
    "  b2 = b2[tmp]\n",
    "\n",
    "  a = np.concatenate((a1, a2))\n",
    "  b = np.concatenate((b1, b2))\n",
    "\n",
    "  c = binary_crossentropy(a, b)\n",
    "  #sess = tf.InteractiveSession()\n",
    "  d = c.eval()\n",
    "  #sess.close()\n",
    "  e = (a-b).reshape(-1)\n",
    "  f = d.reshape(-1)\n",
    "\n",
    "  print len(a1), len(a2), len(b1), len(b2), a1, a2, b1, b2\n",
    "  print len(a), len(b), a, b\n",
    "  print np.min(f), np.max(f), np.median(f)\n",
    "\n",
    "  fig, ax = plt.subplots()\n",
    "  ax.set_yscale('log')\n",
    "  _ = ax.hist(e, bins=50, range=[-10,10])\n",
    "\n",
    "  fig, ax = plt.subplots()\n",
    "  ax.set_yscale('log')\n",
    "  _ = ax.hist(f, bins=50, range=[0,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_h5py():\n",
    "  import h5py\n",
    "\n",
    "  f = h5py.File(model_weights_file)\n",
    "  print f.keys()\n",
    "\n",
    "  keys = [u'dense_1', u'dense_2', u'dense_3', u'regr', u'discr']\n",
    "  for k in keys:\n",
    "    try:\n",
    "      w = f[k][k]['kernel:0'].value\n",
    "      b = f[k][k]['bias:0'].value\n",
    "      print k, w.shape, b.shape, np.min(np.abs(w)), np.max(np.abs(w))\n",
    "      \n",
    "      #FIXME\n",
    "      if k == 'dense_1':\n",
    "        a = np.sum(w*w, axis=0)\n",
    "        b = np.sort(a)/np.sum(a)\n",
    "        print \"..\", a, b\n",
    "    except:\n",
    "      pass\n",
    "\n",
    "if False:\n",
    "  read_h5py()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Current time 2018-07-10 17:19:12.655900\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print('[INFO] Current time {0}'.format(str(datetime.now())))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
