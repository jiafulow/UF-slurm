{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using numpy 1.14.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using keras 2.2.0\n",
      "[INFO] Using tensorflow 1.8.0\n",
      "[INFO] Using sklearn 0.19.1\n",
      "[INFO] Current time 2018-07-10 16:31:32.331681\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(2023)\n",
    "import random\n",
    "random.seed(2023)\n",
    "print('[INFO] Using numpy {0}'.format(np.__version__))\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "old_stdout = sys.stdout\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Dropout, Input, BatchNormalization\n",
    "from keras import initializers, regularizers, optimizers, losses\n",
    "#K.set_epsilon(1e-08)\n",
    "print('[INFO] Using keras {0}'.format(keras.__version__))\n",
    "\n",
    "import tensorflow as tf\n",
    "print('[INFO] Using tensorflow {0}'.format(tf.__version__))\n",
    "\n",
    "import sklearn\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "print('[INFO] Using sklearn {0}'.format(sklearn.__version__))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "%matplotlib inline\n",
    "\n",
    "from datetime import datetime\n",
    "print('[INFO] Current time {0}'.format(str(datetime.now())))\n",
    "\n",
    "\n",
    "# ______________________________________________________________________________\n",
    "# Globals\n",
    "nlayers = 12  # 5 (CSC) + 4 (RPC) + 3 (GEM)\n",
    "\n",
    "nvariables = (nlayers * 5) + 8\n",
    "\n",
    "discr_pt_cut = 14.\n",
    "\n",
    "reg_pt_scale = 100.\n",
    "\n",
    "discr_loss_weight = 1.\n",
    "\n",
    "add_noise = True\n",
    "\n",
    "infile_muon = '/scratch/CMS/L1MuonTrigger/P2_9_2_3_patch1/SingleMuon_Toy_2GeV/histos_tba.13.npz'\n",
    "\n",
    "infile_pileup = '/scratch/CMS/L1MuonTrigger/P2_9_2_3_patch1/SingleMuon_Toy_2GeV/histos_tbd.13.npz'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Encoder(object):\n",
    "\n",
    "  def __init__(self, x, y, adjust_scale=0):\n",
    "    if x is not None and y is not None:\n",
    "      assert(x.shape[1] == (nlayers * 6) + 4)\n",
    "      assert(y.shape[1] == 3)\n",
    "      assert(x.shape[0] == y.shape[0])\n",
    "\n",
    "      self.nentries = x.shape[0]\n",
    "      self.x_orig  = x\n",
    "      self.y_orig  = y\n",
    "      self.x_copy  = x.copy()\n",
    "      self.y_copy  = y.copy()\n",
    "\n",
    "      # Get views\n",
    "      self.x_phi   = self.x_copy[:, nlayers*0:nlayers*1]\n",
    "      self.x_theta = self.x_copy[:, nlayers*1:nlayers*2]\n",
    "      self.x_bend  = self.x_copy[:, nlayers*2:nlayers*3]\n",
    "      self.x_ring  = self.x_copy[:, nlayers*3:nlayers*4]\n",
    "      self.x_fr    = self.x_copy[:, nlayers*4:nlayers*5]\n",
    "      self.x_mask  = self.x_copy[:, nlayers*5:nlayers*6].astype(np.bool)  # this makes a copy\n",
    "      self.x_road  = self.x_copy[:, nlayers*6:nlayers*7]  # ipt, ieta, iphi, iphi_corr\n",
    "      self.y_pt    = self.y_copy[:, 0]  # q/pT\n",
    "      self.y_phi   = self.y_copy[:, 1]\n",
    "      self.y_eta   = self.y_copy[:, 2]\n",
    "      \n",
    "      # Make event weight\n",
    "      #self.w       = np.ones(self.y_pt.shape, dtype=np.float32)\n",
    "      self.w       = np.abs(self.y_pt)/0.2 + 1.0\n",
    "      \n",
    "      # Straightness & zone\n",
    "      self.x_straightness = self.x_road[:, 0][:, np.newaxis]\n",
    "      self.x_zone         = self.x_road[:, 1][:, np.newaxis]\n",
    "      \n",
    "      # Subtract median phi from hit phis\n",
    "      #self.x_phi_median    = self.x_road[:, 2] * 32 - 16  # multiply by 'quadstrip' unit (4 * 8)\n",
    "      self.x_phi_median    = self.x_road[:, 2] * 16 - 8  # multiply by 'doublestrip' unit (2 * 8)\n",
    "      self.x_phi_median    = self.x_phi_median[:, np.newaxis]\n",
    "      self.x_phi          -= self.x_phi_median\n",
    "      \n",
    "      # Subtract median theta from hit thetas\n",
    "      self.x_theta_median  = np.nanmedian(self.x_theta[:,:5], axis=1)  # CSC only\n",
    "      self.x_theta_median[np.isnan(self.x_theta_median)] = np.nanmedian(self.x_theta[np.isnan(self.x_theta_median)], axis=1)  # use all\n",
    "      self.x_theta_median  = self.x_theta_median[:, np.newaxis]\n",
    "      self.x_theta        -= self.x_theta_median\n",
    "      \n",
    "      # Standard scales\n",
    "      # + Remove outlier hits by checking hit thetas\n",
    "      if adjust_scale == 0:  # do not adjust\n",
    "        x_theta_tmp = np.abs(self.x_theta) > 10000.0\n",
    "      elif adjust_scale == 1:  # use mean and std\n",
    "        self.x_mean  = np.nanmean(self.x_copy, axis=0)\n",
    "        self.x_std   = np.nanstd(self.x_copy, axis=0)\n",
    "        self.x_std   = self._handle_zero_in_scale(self.x_std)\n",
    "        self.x_copy -= self.x_mean\n",
    "        self.x_copy /= self.x_std\n",
    "        x_theta_tmp = np.abs(self.x_theta) > 1.0\n",
    "      elif adjust_scale == 2:  # adjust by hand\n",
    "        theta_cuts    = np.array((6., 6., 6., 6., 6., 12., 12., 12., 12., 9., 9., 9.), dtype=np.float32)\n",
    "        x_theta_tmp   = np.abs(self.x_theta) > theta_cuts\n",
    "        self.x_phi   *= 0.000991  # GE1/1 dphi linear correlation with q/pT\n",
    "        self.x_theta *= (1/12.)   # 12 integer theta units\n",
    "        self.x_bend  *= 0.188082  # ME1/2 bend linear correlation with q/pT\n",
    "        x_ring_tmp    = self.x_ring.astype(np.int32)\n",
    "        x_ring_tmp    = (x_ring_tmp == 1) | (x_ring_tmp == 4)\n",
    "        self.x_ring[x_ring_tmp] = 0  # ring 1,4 -> 0\n",
    "        self.x_ring[~x_ring_tmp] = 1 # ring 2,3 -> 1\n",
    "        x_fr_tmp      = self.x_fr.astype(np.int32)\n",
    "        x_fr_tmp      = (x_fr_tmp == 0)\n",
    "        self.x_fr[x_fr_tmp] = 0\n",
    "        self.x_fr[~x_fr_tmp] = 1\n",
    "      elif adjust_scale == 3:  # adjust by hand #2\n",
    "        #theta_cuts    = np.array((6., 6., 6., 6., 6., 12., 12., 12., 12., 9., 9., 9.), dtype=np.float32)\n",
    "        theta_cuts    = np.array((6., 6., 6., 6., 6., 10., 10., 10., 10., 8., 8., 8.), dtype=np.float32)\n",
    "        x_theta_tmp   = np.abs(self.x_theta) > theta_cuts\n",
    "        x_ring_tmp    = self.x_ring.astype(np.int32)\n",
    "        x_ring_tmp    = (x_ring_tmp == 1) | (x_ring_tmp == 4)\n",
    "        self.x_ring[x_ring_tmp] = 0  # ring 1,4 -> 0\n",
    "        self.x_ring[~x_ring_tmp] = 1 # ring 2,3 -> 1\n",
    "        x_fr_tmp      = self.x_fr.astype(np.int32)\n",
    "        x_fr_tmp      = (x_fr_tmp == 0)\n",
    "        self.x_fr[x_fr_tmp] = 0\n",
    "        self.x_fr[~x_fr_tmp] = 1\n",
    "        s = [ 0.00528005,  0.01100854, -0.01955833, -0.01326062, -0.00839341,\n",
    "              0.01209313, -0.02546741, -0.011541  , -0.00734255,  0.00393156,\n",
    "             -0.02459449,  1.        ,  0.55500895,  0.50743203,  1.4219028 ,\n",
    "              1.35162982,  0.93576706,  0.19965793,  0.29495697,  0.35250728,\n",
    "              0.38013349,  0.50885451,  0.66930139,  1.        ,  0.81924683,\n",
    "              0.47289819,  1.67281557,  1.1339659 ,  1.13266964,  1.        ,\n",
    "              1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
    "              1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
    "              1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
    "              1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
    "              1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
    "              1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
    "              1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
    "              1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
    "              1.        ,  1.        ,  1.        ,  1.        ,  1.        ,  1.        ]\n",
    "        self.x_copy *= s\n",
    "      \n",
    "      # Remove outlier hits by checking hit thetas\n",
    "      self.x_phi  [x_theta_tmp] = np.nan\n",
    "      self.x_theta[x_theta_tmp] = np.nan\n",
    "      self.x_bend [x_theta_tmp] = np.nan\n",
    "      self.x_ring [x_theta_tmp] = np.nan\n",
    "      self.x_fr   [x_theta_tmp] = np.nan\n",
    "      self.x_mask [x_theta_tmp] = 1.0\n",
    "      \n",
    "      # Add variables: straightness, zone, theta_median and mode variables\n",
    "      self.x_straightness = np.abs(self.x_straightness - 6.) / 6.  # scaled to [0,1]\n",
    "      self.x_zone         = (self.x_zone - 0.) / 5.  # scaled to [0,1]\n",
    "      self.x_theta_median = (self.x_theta_median - 3.) / 83.  # scaled to [0,1]\n",
    "      hits_to_station = np.array((5,1,2,3,4,1,2,3,4,5,2,5), dtype=np.int32)  # '5' denotes ME1/1\n",
    "      assert(len(hits_to_station) == nlayers)\n",
    "      self.x_mode_vars = np.zeros((self.nentries, 5), dtype=np.bool)\n",
    "      self.x_mode_vars[:,0] = np.any(self.x_mask[:,hits_to_station == 5] == 0, axis=1)\n",
    "      self.x_mode_vars[:,1] = np.any(self.x_mask[:,hits_to_station == 1] == 0, axis=1)\n",
    "      self.x_mode_vars[:,2] = np.any(self.x_mask[:,hits_to_station == 2] == 0, axis=1)\n",
    "      self.x_mode_vars[:,3] = np.any(self.x_mask[:,hits_to_station == 3] == 0, axis=1)\n",
    "      self.x_mode_vars[:,4] = np.any(self.x_mask[:,hits_to_station == 4] == 0, axis=1)\n",
    "      \n",
    "      # Remove NaN\n",
    "      #np.nan_to_num(self.x_copy, copy=False)\n",
    "      self.x_copy[np.isnan(self.x_copy)] = 0.0\n",
    "\n",
    "  # Copied from scikit-learn\n",
    "  def _handle_zero_in_scale(self, scale):\n",
    "    scale[scale == 0.0] = 1.0\n",
    "    return scale\n",
    "\n",
    "  def get_x(self):\n",
    "    #x_new = self.x_phi\n",
    "    x_new = np.hstack((self.x_phi, self.x_theta, self.x_bend, self.x_ring, self.x_fr, self.x_straightness, self.x_zone, self.x_theta_median, self.x_mode_vars))\n",
    "    return x_new\n",
    "\n",
    "  def get_x_mask(self):\n",
    "    x_mask = self.x_mask.copy()\n",
    "    return x_mask\n",
    "\n",
    "  def get_y(self):\n",
    "    y_new = self.y_pt.copy()\n",
    "    return y_new\n",
    "\n",
    "  def get_w(self):\n",
    "    w_new = self.w.copy()\n",
    "    return w_new\n",
    "\n",
    "  def save_encoder(self, filepath):\n",
    "    np.savez_compressed(filepath, x_mean=self.x_mean, x_std=self.x_std)\n",
    "\n",
    "  def load_endcoder(self, filepath):\n",
    "    loaded = np.load(filepath)\n",
    "    self.x_mean = loaded['x_mean']\n",
    "    self.x_std = loaded['x_std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "# ______________________________________________________________________________\n",
    "# New leaky relu\n",
    "def NewLeakyReLU(x, alpha=0., max_value=None):\n",
    "  return K.relu(x, alpha=alpha, max_value=max_value)\n",
    "\n",
    "# ______________________________________________________________________________\n",
    "# New tanh\n",
    "def NewTanh(x):\n",
    "  return K.tanh(x)\n",
    "  #return 1.7159 * K.tanh(x * 2./3.)\n",
    "  #return K.clip(x, -1., 1.)\n",
    "\n",
    "# ______________________________________________________________________________\n",
    "# Huber loss\n",
    "def huber_loss(y_true, y_pred, delta=1.345):\n",
    "  x = K.abs(y_true - y_pred)\n",
    "  squared_loss = 0.5*K.square(x)\n",
    "  absolute_loss = delta * (x - 0.5*delta)\n",
    "  #xx = K.switch(x < delta, squared_loss, absolute_loss)\n",
    "  xx = tf.where(x < delta, squared_loss, absolute_loss)  # needed for tensorflow\n",
    "  return K.mean(xx, axis=-1)\n",
    "\n",
    "def masked_huber_loss(y_true, y_pred, delta=1.345):\n",
    "  x = K.abs(y_true - y_pred)\n",
    "  squared_loss = 0.5*K.square(x)\n",
    "  absolute_loss = delta * (x - 0.5*delta)\n",
    "  #xx = K.switch(x < delta, squared_loss, absolute_loss)\n",
    "  xx = tf.where(x < delta, squared_loss, absolute_loss)  # needed for tensorflow\n",
    "\n",
    "  mask_value = 100.\n",
    "  mask = K.not_equal(y_true, mask_value)\n",
    "  mask = K.cast(mask, K.floatx())\n",
    "  xx *= mask\n",
    "  xx /= K.mean(mask)\n",
    "  return K.mean(xx, axis=-1)\n",
    "\n",
    "#def masked_huber_loss(y_true, y_pred, delta=1.345):\n",
    "#  mask_value = 100.\n",
    "#  mask_alpha = 0.02\n",
    "#  mask_target = 0.5 * reg_pt_scale\n",
    "#  mask = K.equal(y_true, mask_value)\n",
    "#  \n",
    "#  #x = K.abs(y_true - y_pred)\n",
    "#  x = tf.where(mask, mask_alpha * K.abs(mask_target - K.abs(y_pred)), K.abs(y_true - y_pred))\n",
    "#  squared_loss = 0.5*K.square(x)\n",
    "#  absolute_loss = delta * (x - 0.5*delta)\n",
    "#  #xx = K.switch(x < delta, squared_loss, absolute_loss)\n",
    "#  xx = tf.where(x < delta, squared_loss, absolute_loss)  # needed for tensorflow\n",
    "#  return K.mean(xx, axis=-1)\n",
    "\n",
    "\n",
    "# ______________________________________________________________________________\n",
    "# Binary crossentropy\n",
    "def masked_binary_crossentropy(y_true, y_pred, from_logits=False):\n",
    "  target, output = y_true, y_pred\n",
    "\n",
    "  # transform back to logits\n",
    "  if not from_logits:\n",
    "    output = K.clip(output, K.epsilon(), 1 - K.epsilon())\n",
    "    output = K.log(output / (1 - output))\n",
    "  \n",
    "  xx =  tf.nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n",
    "  #xx =  tf.nn.weighted_cross_entropy_with_logits(targets=target, logits=output, pos_weight=0.5)  # pos_weight < 1 decreases the false positive count\n",
    "\n",
    "  mask_value = 100.\n",
    "  mask = K.not_equal(y_true, mask_value)\n",
    "  mask = K.cast(mask, K.floatx())\n",
    "  xx *= mask\n",
    "  xx /= K.mean(mask)\n",
    "  return K.mean(xx, axis=-1)\n",
    "\n",
    "\n",
    "# ______________________________________________________________________________\n",
    "# Learning rate decay by epoch number\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "  if (epoch % 10) == 0:\n",
    "    lr = K.get_value(model.optimizer.lr)\n",
    "    K.set_value(model.optimizer.lr, lr*0.95)\n",
    "    print(\"lr changed to {}\".format(lr*0.95))\n",
    "  return K.get_value(model.optimizer.lr)\n",
    "\n",
    "lr_decay = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "\n",
    "# ______________________________________________________________________________\n",
    "# Custom objects\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "\n",
    "get_custom_objects().update({'masked_huber_loss': masked_huber_loss, 'masked_binary_crossentropy': masked_binary_crossentropy, 'NewLeakyReLU': NewLeakyReLU, 'NewTanh': NewTanh})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading muon data ...\n",
      "[INFO] Loaded the variables with shape (3643811, 76)\n",
      "[INFO] Loaded the parameters with shape (3643811, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uf/jlow/jftest2/miniconda3/envs/tensorflow_conda/lib/python2.7/site-packages/numpy/lib/function_base.py:4033: RuntimeWarning: All-NaN slice encountered\n",
      "  r = func(a, **kwargs)\n",
      "/home/uf/jlow/jftest2/miniconda3/envs/tensorflow_conda/lib/python2.7/site-packages/ipykernel_launcher.py:75: RuntimeWarning: invalid value encountered in greater\n"
     ]
    }
   ],
   "source": [
    "#### Load data ####\n",
    "\n",
    "def muon_data():\n",
    "  try:\n",
    "    print('[INFO] Loading muon data ...')\n",
    "    loaded = np.load(infile_muon)\n",
    "    the_variables = loaded['variables']\n",
    "    the_parameters = loaded['parameters']\n",
    "    print('[INFO] Loaded the variables with shape {0}'.format(the_variables.shape))\n",
    "    print('[INFO] Loaded the parameters with shape {0}'.format(the_parameters.shape))\n",
    "  except:\n",
    "    print('[ERROR] Failed to load data from file: {0}'.format(infile_muon))\n",
    "\n",
    "  encoder = Encoder(the_variables, the_parameters, adjust_scale=3)\n",
    "  x, y, w, x_mask = encoder.get_x(), encoder.get_y(), encoder.get_w(), encoder.get_x_mask()\n",
    "  assert np.isfinite(x).all()\n",
    "\n",
    "  # Split dataset in training and testing\n",
    "  x_train, x_test, y_train, y_test, w_train, w_test, x_mask_train, x_mask_test = train_test_split(x, y, w, x_mask, test_size=0.3)\n",
    "  return x_train, x_test, y_train, y_test, w_train, w_test, x_mask_train, x_mask_test\n",
    "\n",
    "# ______________________________________________________________________________\n",
    "x_train, x_test, y_train, y_test, w_train, w_test, x_mask_train, x_mask_test = muon_data()\n",
    "\n",
    "# Add output nodes\n",
    "labels = np.where(np.abs(1.0/y_train) > discr_pt_cut, 1., 100.)  # mask_value is set to 100\n",
    "y_train = [y_train, labels.astype(np.float32)]\n",
    "\n",
    "labels = np.where(np.abs(1.0/y_test) > discr_pt_cut, 1., 100.)  # mask_value is set to 100\n",
    "y_test = [y_test, labels.astype(np.float32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading pileup data ...\n",
      "[INFO] Loaded the variables with shape (171550, 76)\n",
      "[INFO] Loaded the auxiliary info with shape (171550, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uf/jlow/jftest2/miniconda3/envs/tensorflow_conda/lib/python2.7/site-packages/ipykernel_launcher.py:75: RuntimeWarning: invalid value encountered in greater\n"
     ]
    }
   ],
   "source": [
    "#### Load data (pileup) ####\n",
    "\n",
    "def pileup_data():\n",
    "  try:\n",
    "    print('[INFO] Loading pileup data ...')\n",
    "    loaded = np.load(infile_pileup)\n",
    "    the_variables = loaded['variables']\n",
    "    the_parameters = np.zeros((the_variables.shape[0], 3), dtype=np.float32)\n",
    "    the_auxiliaries = loaded['aux']\n",
    "    print('[INFO] Loaded the variables with shape {0}'.format(the_variables.shape))\n",
    "    print('[INFO] Loaded the auxiliary info with shape {0}'.format(the_auxiliaries.shape))\n",
    "  except:\n",
    "    print('[ERROR] Failed to load data from file: {0}'.format(infile_pileup))\n",
    "\n",
    "  sel = the_auxiliaries[:,2] > discr_pt_cut\n",
    "  the_variables = the_variables[~sel]\n",
    "  the_parameters = the_parameters[~sel]\n",
    "  the_auxiliaries = the_auxiliaries[~sel]\n",
    "\n",
    "  encoder = Encoder(the_variables, the_parameters, adjust_scale=3)\n",
    "  x, y, w, x_mask = encoder.get_x(), encoder.get_y(), encoder.get_w(), encoder.get_x_mask()\n",
    "  aux = the_auxiliaries  # jobid, ievt, highest_part_pt, highest_track_pt\n",
    "  assert np.isfinite(x).all()\n",
    "\n",
    "  # Split dataset in training and testing\n",
    "  split = the_auxiliaries[:,0] < 50.\n",
    "  x_train, x_test, aux_train, aux_test = x[~split], x[split], aux[~split], aux[split]\n",
    "  return x_train, x_test, aux_train, aux_test\n",
    "\n",
    "# ______________________________________________________________________________\n",
    "x_adv_train, x_adv_test, aux_adv_train, aux_adv_test = pileup_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### Create a model ####\n",
    "\n",
    "# See https://keras.io/models/about-keras-models/\n",
    "#     https://keras.io/layers/about-keras-layers/\n",
    "#     https://keras.io/getting-started/functional-api-guide/#getting-started-with-the-keras-functional-api\n",
    "\n",
    "def create_model():\n",
    "  inputs = Input(shape=(nvariables,), dtype='float32')\n",
    "\n",
    "  x = Dense(64, activation='tanh', kernel_initializer='glorot_uniform', kernel_regularizer=regularizers.l2(0.0000))(inputs)\n",
    "  #x = Dropout(0.2)(x)\n",
    "  x = Dense(32, activation='tanh', kernel_initializer='glorot_uniform', kernel_regularizer=regularizers.l2(0.0000))(x)\n",
    "  #x = Dropout(0.2)(x)\n",
    "  x = Dense(16, activation='tanh', kernel_initializer='glorot_uniform', kernel_regularizer=regularizers.l2(0.0000))(x)\n",
    "  #x = Dropout(0.2)(x)\n",
    "\n",
    "  regr = Dense(1, activation='linear', kernel_initializer='glorot_uniform', name='regr')(x)\n",
    "  discr = Dense(1, activation='sigmoid', kernel_initializer='glorot_uniform', name='discr')(x)\n",
    "\n",
    "  # This creates a model that includes\n",
    "  # the Input layer, three Dense layers and the Output layer\n",
    "  model = Model(inputs=inputs, outputs=[regr, discr])\n",
    "\n",
    "  # Set loss and optimizers\n",
    "  #binary_crossentropy = losses.binary_crossentropy\n",
    "  #mean_squared_error = losses.mean_squared_error\n",
    "\n",
    "  adam = optimizers.Adam(lr=0.00113)\n",
    "  #adam = optimizers.Adam(lr=0.001)  # default\n",
    "  #adam = optimizers.Adam(lr=0.01)\n",
    "  #adam = optimizers.Adam(lr=0.001, amsgrad=True)\n",
    "\n",
    "  # Compile\n",
    "  model.compile(optimizer=adam,\n",
    "    loss={'regr': masked_huber_loss, 'discr': masked_binary_crossentropy},\n",
    "    loss_weights={'regr': 1.0, 'discr': discr_loss_weight},\n",
    "    #metrics={'regr': ['acc', 'mse', 'mae'], 'discr': ['acc',]}\n",
    "    )\n",
    "  return model\n",
    "\n",
    "def create_model_sequential():\n",
    "  model = Sequential()\n",
    "  model.add(Dense(64, input_dim=nvariables, activation='tanh', kernel_initializer='glorot_uniform', kernel_regularizer=regularizers.l2(0.0000)))\n",
    "  #model.add(Dropout(0.2))\n",
    "  model.add(Dense(32, activation='tanh', kernel_initializer='glorot_uniform', kernel_regularizer=regularizers.l2(0.0000)))\n",
    "  #model.add(Dropout(0.2))\n",
    "  model.add(Dense(16, activation='tanh', kernel_initializer='glorot_uniform', kernel_regularizer=regularizers.l2(0.0000)))\n",
    "  #model.add(Dropout(0.2))\n",
    "  model.add(Dense(1, activation='linear', kernel_initializer='glorot_uniform'))\n",
    "  \n",
    "  adam = optimizers.Adam(lr=0.001)\n",
    "  model.compile(loss=huber_loss, optimizer=adam, metrics=['acc'])\n",
    "  return model\n",
    "\n",
    "def save_model(model):\n",
    "  # Store model to file\n",
    "  model.summary()\n",
    "  model.save('model.h5')\n",
    "  model.save_weights('model_weights.h5')\n",
    "\n",
    "  # Store model to json\n",
    "  import json\n",
    "  with open('model.json', 'w') as outfile:\n",
    "    outfile.write(model.to_json())\n",
    "  return\n",
    "\n",
    "# ______________________________________________________________________________\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### Training Functions ####\n",
    "\n",
    "# from https://github.com/keras-team/keras/blob/master/keras/utils/generic_utils.py\n",
    "def slice_arrays(arrays, start=None, stop=None):\n",
    "    \"\"\"Slices an array or list of arrays.\n",
    "    This takes an array-like, or a list of\n",
    "    array-likes, and outputs:\n",
    "        - arrays[start:stop] if `arrays` is an array-like\n",
    "        - [x[start:stop] for x in arrays] if `arrays` is a list\n",
    "    Can also work on list/array of indices: `_slice_arrays(x, indices)`\n",
    "    # Arguments\n",
    "        arrays: Single array or list of arrays.\n",
    "        start: can be an integer index (start index)\n",
    "            or a list/array of indices\n",
    "        stop: integer (stop index); should be None if\n",
    "            `start` was a list.\n",
    "    # Returns\n",
    "        A slice of the array(s).\n",
    "    \"\"\"\n",
    "    if arrays is None:\n",
    "        return [None]\n",
    "    elif isinstance(arrays, list):\n",
    "        if hasattr(start, '__len__'):\n",
    "            # hdf5 datasets only support list objects as indices\n",
    "            if hasattr(start, 'shape'):\n",
    "                start = start.tolist()\n",
    "            return [None if x is None else x[start] for x in arrays]\n",
    "        else:\n",
    "            return [None if x is None else x[start:stop] for x in arrays]\n",
    "    else:\n",
    "        if hasattr(start, '__len__'):\n",
    "            if hasattr(start, 'shape'):\n",
    "                start = start.tolist()\n",
    "            return arrays[start]\n",
    "        elif hasattr(start, '__getitem__'):\n",
    "            return arrays[start:stop]\n",
    "        else:\n",
    "            return [None]\n",
    "\n",
    "\n",
    "def merge_arrays(arrays, arrays_to_add):\n",
    "    if isinstance(arrays, list):\n",
    "        return [None if x is None else np.concatenate((x,y)) for (x,y) in zip(arrays, arrays_to_add)]\n",
    "    else:\n",
    "        return [None]\n",
    "\n",
    "# from https://github.com/keras-team/keras/blob/master/keras/engine/training_utils.py\n",
    "def make_batches(size, batch_size):\n",
    "    \"\"\"Returns a list of batch indices (tuples of indices).\n",
    "    # Arguments\n",
    "        size: Integer, total size of the data to slice into batches.\n",
    "        batch_size: Integer, batch size.\n",
    "    # Returns\n",
    "        A list of tuples of array indices.\n",
    "    \"\"\"\n",
    "    num_batches = (size + batch_size - 1) // batch_size  # round up\n",
    "    return [(i * batch_size, min(size, (i + 1) * batch_size))\n",
    "            for i in range(num_batches)]\n",
    "\n",
    "# ______________________________________________________________________________\n",
    "# from https://github.com/keras-team/keras/blob/2.0.5/keras/engine/training.py\n",
    "\n",
    "import copy\n",
    "from keras import callbacks as cbks\n",
    "from keras.utils.generic_utils import Progbar\n",
    "\n",
    "def train(model, x, y, x_adv, aux_adv, batch_size=None, epochs=1, verbose=1, callbacks=None,\n",
    "          validation_split=0., shuffle=True, class_weight=None, sample_weight=None):\n",
    "  \n",
    "  # Validate user data.\n",
    "  x, y, sample_weights = model._standardize_user_data(\n",
    "    x, y,\n",
    "    sample_weight=sample_weight,\n",
    "    class_weight=class_weight,\n",
    "    batch_size=batch_size)\n",
    "  \n",
    "  y = [y[0] * reg_pt_scale, y[1]]\n",
    "  \n",
    "  # Prepare input arrays\n",
    "  if model.uses_learning_phase and not isinstance(K.learning_phase(), int):\n",
    "    ins = x + y + sample_weights + [1.]\n",
    "  else:\n",
    "    ins = x + y + sample_weights\n",
    "\n",
    "  #print('[INFO] ins shapes: {0}'.format([xx.shape for xx in ins]))\n",
    "  \n",
    "  # Prepare validation data.\n",
    "  do_validation = False\n",
    "  if validation_split and 0. < validation_split < 1.:\n",
    "    do_validation = True\n",
    "    if hasattr(x[0], 'shape'):\n",
    "      split_at = int(x[0].shape[0] * (1. - validation_split))\n",
    "    else:\n",
    "      split_at = int(len(x[0]) * (1. - validation_split))\n",
    "    x, val_x = (slice_arrays(x, 0, split_at), slice_arrays(x, split_at))\n",
    "    y, val_y = (slice_arrays(y, 0, split_at), slice_arrays(y, split_at))\n",
    "    sample_weights, val_sample_weights = (slice_arrays(sample_weights, 0, split_at), slice_arrays(sample_weights, split_at))\n",
    "    if model.uses_learning_phase and not isinstance(K.learning_phase(), int):\n",
    "      val_ins = val_x + val_y + val_sample_weights + [0.]\n",
    "    else:\n",
    "      val_ins = val_x + val_y + val_sample_weights\n",
    "  else:\n",
    "    val_ins = []\n",
    "\n",
    "  # logic from `_fit_loop()`\n",
    "  num_train_samples = x[0].shape[0]\n",
    "  index_array = np.arange(num_train_samples)\n",
    "  num_test_samples = val_x[0].shape[0]\n",
    "  val_index_array = np.arange(num_test_samples)\n",
    "  \n",
    "  # Callbacks\n",
    "  out_labels = model.metrics_names\n",
    "  if do_validation:\n",
    "    callback_metrics = copy.copy(out_labels) + ['val_' + n for n in out_labels]\n",
    "  else:\n",
    "    callback_metrics = copy.copy(out_labels)\n",
    "\n",
    "  model.history = cbks.History()\n",
    "  callbacks = [cbks.BaseLogger()] + (callbacks or []) + [model.history]\n",
    "  if verbose:\n",
    "    callbacks += [cbks.ProgbarLogger()]\n",
    "  callbacks = cbks.CallbackList(callbacks)\n",
    "  callback_model = model\n",
    "  callbacks.set_model(callback_model)\n",
    "  callbacks.set_params({\n",
    "      'batch_size': batch_size,\n",
    "      'epochs': epochs,\n",
    "      'samples': num_train_samples,\n",
    "      'verbose': verbose,\n",
    "      'do_validation': do_validation,\n",
    "      'metrics': callback_metrics or [],\n",
    "  })\n",
    "  callbacks.on_train_begin()\n",
    "  callback_model.stop_training = False\n",
    "  for cbk in callbacks:\n",
    "      cbk.validation_data = val_ins\n",
    "  \n",
    "  \n",
    "  # Loop over epochs\n",
    "  for epoch in xrange(epochs):\n",
    "    epoch_logs = {}\n",
    "    callbacks.on_epoch_begin(epoch)\n",
    "    \n",
    "    if shuffle:\n",
    "      np.random.shuffle(index_array)\n",
    "      #np.random.shuffle(val_index_array)\n",
    "    \n",
    "    batches = make_batches(num_train_samples, batch_size)\n",
    "    \n",
    "    # Loop over batches\n",
    "    for batch_index, (batch_start, batch_end) in enumerate(batches):\n",
    "      batch_ids = index_array[batch_start:batch_end]\n",
    "      if ins and isinstance(ins[-1], float):\n",
    "        # Do not slice the training phase flag.\n",
    "        ins_batch = slice_arrays(ins[:-1], batch_ids) + [ins[-1]]\n",
    "        assert isinstance(ins_batch, list) and len(ins_batch) == 1 + 2 + 2 + 1\n",
    "      else:\n",
    "        ins_batch = slice_arrays(ins, batch_ids)\n",
    "        assert isinstance(ins_batch, list) and len(ins_batch) == 1 + 2 + 2\n",
    "      \n",
    "      # Add noise (pileup)\n",
    "      if add_noise:\n",
    "        #noise = x_adv[np.random.randint(0, x_adv.shape[0], ins_batch[0].shape[0])]\n",
    "        #noise_reg = np.zeros_like(ins_batch[1]) + 100.  # mask_value is set to 100\n",
    "        #noise_discr = np.zeros_like(ins_batch[2])\n",
    "        #noise_reg_w = np.ones_like(ins_batch[3])\n",
    "        #noise_discr_w = np.ones_like(ins_batch[3])\n",
    "        n = np.sum(np.equal(ins_batch[2],1.))\n",
    "        noise = x_adv[np.random.randint(0, x_adv.shape[0], n)]\n",
    "        noise_reg = np.zeros((n,1)) + 100.  # mask_value is set to 100\n",
    "        noise_discr = np.zeros((n,1))\n",
    "        noise_reg_w = np.ones((n,))\n",
    "        noise_discr_w = np.ones((n,))\n",
    "        ins_noise = [noise, noise_reg, noise_discr, noise_reg_w, noise_discr_w]\n",
    "        if ins and isinstance(ins[-1], float):\n",
    "          ins_batch = merge_arrays(ins_batch[:-1], ins_noise) + [ins_batch[-1]]\n",
    "        else:\n",
    "          ins_batch = merge_arrays(ins_batch, ins_noise)\n",
    "      \n",
    "      batch_logs = {}\n",
    "      batch_logs['batch'] = batch_index\n",
    "      batch_logs['size'] = len(batch_ids)\n",
    "      callbacks.on_batch_begin(batch_index, batch_logs)\n",
    "      \n",
    "      # Magic\n",
    "      model._make_train_function()\n",
    "      f = model.train_function\n",
    "      outs = f(ins_batch)\n",
    "      \n",
    "      if not isinstance(outs, list):\n",
    "        outs = [outs]\n",
    "      for l, o in zip(out_labels, outs):\n",
    "        batch_logs[l] = o\n",
    "      \n",
    "      callbacks.on_batch_end(batch_index, batch_logs)\n",
    "      if callback_model.stop_training:\n",
    "        break\n",
    "      \n",
    "      if batch_index == len(batches) - 1:  # Last batch.\n",
    "        if do_validation:\n",
    "          # logic from `_test_loop()`\n",
    "          val_batches = make_batches(num_test_samples, batch_size)\n",
    "          val_outs = []\n",
    "          if verbose == 1:\n",
    "            progbar = Progbar(target=num_test_samples)\n",
    "          \n",
    "          for val_batch_index, (val_batch_start, val_batch_end) in enumerate(val_batches):\n",
    "            val_batch_ids = val_index_array[val_batch_start:val_batch_end]\n",
    "            if isinstance(val_ins[-1], float):\n",
    "              # Do not slice the training phase flag.\n",
    "              val_ins_batch = slice_arrays(val_ins[:-1], val_batch_ids) + [val_ins[-1]]\n",
    "            else:\n",
    "              val_ins_batch = slice_arrays(val_ins, val_batch_ids)\n",
    "            \n",
    "            # Magic\n",
    "            model._make_test_function()\n",
    "            val_f = model.test_function\n",
    "            val_batch_outs = val_f(val_ins_batch)\n",
    "            \n",
    "            if isinstance(val_batch_outs, list):\n",
    "              if val_batch_index == 0:\n",
    "                for i, val_batch_out in enumerate(val_batch_outs):\n",
    "                  val_outs.append(0.)\n",
    "              for i, val_batch_out in enumerate(val_batch_outs):\n",
    "                val_outs[i] += val_batch_out * len(val_batch_ids)\n",
    "            else:\n",
    "              if val_batch_index == 0:\n",
    "                val_outs.append(0.)\n",
    "              val_outs[0] += val_batch_outs * len(val_batch_ids)\n",
    "            \n",
    "            if verbose == 1:\n",
    "              progbar.update(val_batch_end)\n",
    "            \n",
    "          if not isinstance(val_outs, list):\n",
    "            val_outs = [val_outs]\n",
    "          # Same labels assumed.\n",
    "          for l, o in zip(out_labels, val_outs):\n",
    "            o /= num_test_samples\n",
    "            epoch_logs['val_' + l] = o\n",
    "            \n",
    "    callbacks.on_epoch_end(epoch, epoch_logs)\n",
    "    if callback_model.stop_training:\n",
    "      break\n",
    "\n",
    "  callbacks.on_train_end()\n",
    "  return model.history\n",
    "\n",
    "# ______________________________________________________________________________\n",
    "def predict(model, x):\n",
    "  outs = model.predict(x)\n",
    "  outs[0] /= reg_pt_scale\n",
    "  return outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Begin training ...\n",
      "[INFO] Time elapsed: 922.48460412 sec\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 68)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           4416        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           2080        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 16)           528         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "regr (Dense)                    (None, 1)            17          dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "discr (Dense)                   (None, 1)            17          dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 7,058\n",
      "Trainable params: 7,058\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "[INFO] Done training.\n",
      "[INFO] Model is saved as model.h5, model.json and model_weights.h5\n"
     ]
    }
   ],
   "source": [
    "#### Training ####\n",
    "\n",
    "print('[INFO] Begin training ...')\n",
    "assert keras.backend.backend() == 'tensorflow'\n",
    "\n",
    "start_time = time.time()\n",
    "sys.stdout = open('keras_output_1.txt', 'w')\n",
    "#history = model.fit(x_train, y_train, epochs=20, validation_split=0.1, batch_size=256, verbose=1)\n",
    "#history = model.fit(x_train, y_train, epochs=200, validation_split=0.1, batch_size=256, callbacks=[lr_decay], verbose=0)\n",
    "history = train(model, x_train, y_train, x_adv_train, aux_adv_train, epochs=10, validation_split=0.1, batch_size=128, verbose=1)\n",
    "#history = train(model, x_train, y_train, x_adv_train, aux_adv_train, epochs=300, validation_split=0.1, batch_size=128, callbacks=[lr_decay], verbose=1)\n",
    "sys.stdout.close()\n",
    "sys.stdout = old_stdout\n",
    "print('[INFO] Time elapsed: {0} sec'.format(time.time() - start_time))\n",
    "\n",
    "save_model(model)\n",
    "print('[INFO] Done training.')\n",
    "print('[INFO] Model is saved as model.h5, model.json and model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093144/1093144 [==============================] - 2s 2us/step\n",
      "[INFO] loss and metrics: [30.123472860657674, 30.090791997355876, 0.03268084095076325]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### Evaluation ####\n",
    "\n",
    "#loss_and_metrics = model.evaluate(x_test, y_test, sample_weight=w_test, batch_size=1000)\n",
    "loss_and_metrics = model.evaluate(x_test, y_test, batch_size=1000)\n",
    "print('[INFO] loss and metrics: {0}'.format(loss_and_metrics))\n",
    "\n",
    "# Loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['regr_loss'])\n",
    "plt.plot(history.history['val_regr_loss'])\n",
    "plt.title('regr loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['discr_loss'])\n",
    "plt.plot(history.history['val_discr_loss'])\n",
    "plt.title('discr loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "## Mean Squared Error\n",
    "#plt.plot(history.history['regr_mean_squared_error'])\n",
    "#plt.plot(history.history['val_regr_mean_squared_error'])\n",
    "#plt.title('regr mse')\n",
    "#plt.ylabel('mse')\n",
    "#plt.xlabel('epoch')\n",
    "#plt.legend(['train', 'validation'], loc='upper left')\n",
    "#plt.show()\n",
    "\n",
    "## Mean Absolute Error\n",
    "#plt.plot(history.history['regr_mean_absolute_error'])\n",
    "#plt.plot(history.history['val_regr_mean_absolute_error'])\n",
    "#plt.title('regr mae')\n",
    "#plt.ylabel('mae')\n",
    "#plt.xlabel('epoch')\n",
    "#plt.legend(['train', 'validation'], loc='upper left')\n",
    "#plt.show()\n",
    "\n",
    "## Accuracy\n",
    "#plt.plot(history.history['discr_acc'])\n",
    "#plt.plot(history.history['val_discr_acc'])\n",
    "#plt.title('discr accuracy')\n",
    "#plt.ylabel('accuracy')\n",
    "#plt.xlabel('epoch')\n",
    "#plt.legend(['train', 'validation'], loc='upper left')\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Make plots ####\n",
    "\n",
    "from keras.models import load_model\n",
    "import ROOT\n",
    "\n",
    "# Load model\n",
    "model_file = 'model.h5'\n",
    "model_weights_file = 'model_weights.h5'\n",
    "\n",
    "loaded_model = load_model(model_file)\n",
    "loaded_model.load_weights(model_weights_file)\n",
    "\n",
    "# Set styles\n",
    "ROOT.gROOT.LoadMacro(\"tdrstyle.C\")\n",
    "ROOT.gROOT.ProcessLine(\"setTDRStyle();\")\n",
    "ROOT.gStyle.SetPalette(57)  # kBird\n",
    "ROOT.gStyle.SetMarkerStyle(1)\n",
    "ROOT.gStyle.SetEndErrorSize(0)\n",
    "ROOT.gStyle.SetPadGridX(True)\n",
    "ROOT.gStyle.SetPadGridY(True)\n",
    "\n",
    "nentries_test = x_test.shape[0]/10\n",
    "#nentries_test = 100000\n",
    "\n",
    "y_test_meas = predict(loaded_model, x_test[:nentries_test, :])\n",
    "\n",
    "y_adv_test = [np.zeros((x_adv_test.shape[0],1), dtype=np.float32), np.zeros((x_adv_test.shape[0],1), dtype=np.float32)]\n",
    "y_adv_test_meas = predict(loaded_model, x_adv_test)\n",
    "\n",
    "print y_test[:nentries_test]\n",
    "print y_test_meas\n",
    "print y_adv_test_meas"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# For regression\n",
    "h1 = ROOT.TH1F(\"h1\", \"h1\", 300, -0.3, 0.3)\n",
    "h2a = ROOT.TH2F(\"h2a\", \"h2a\", 100, -0.5, 0.5, 300, -0.3, 0.3)\n",
    "h2b = ROOT.TH2F(\"h2b\", \"h2b\", 100, -0.5, 0.5, 300, -0.5, 0.5)\n",
    "h2c = ROOT.TH2F(\"h2c\", \"h2c\", 100, -0.5, 0.5, 400, -2, 2)\n",
    "h2d = ROOT.TH2F(\"h2d\", \"h2d\", 100, -0.5, 0.5, 400, -2, 2)\n",
    "h2e = ROOT.TH2F(\"h2e\", \"h2e\", 100, 0., 0.5, 400, -2, 2)\n",
    "\n",
    "for i in xrange(nentries_test):\n",
    "  y_true = y_test[0][i]\n",
    "  y_meas = y_test_meas[0][i]\n",
    "  h1.Fill(y_meas - y_true)\n",
    "  h2a.Fill(y_true, y_meas - y_true) \n",
    "  h2b.Fill(y_true, y_meas)\n",
    "  h2c.Fill(y_true, (y_meas - y_true)/abs(y_true))\n",
    "  h2d.Fill(y_true, (abs(1.0/y_meas) - abs(1.0/y_true))/abs(1.0/y_true))\n",
    "  h2e.Fill(abs(y_true), (abs(1.0/y_meas) - abs(1.0/y_true))/abs(1.0/y_true))\n",
    "\n",
    "\n",
    "c = ROOT.TCanvas()\n",
    "h1.SetMarkerStyle(20)\n",
    "h1.Draw()\n",
    "c.Draw()\n",
    "print h1.GetEntries(), h1.GetMean(), h1.GetRMS()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "c = ROOT.TCanvas()\n",
    "h2a.Draw(\"COLZ\")\n",
    "c.Draw()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "c = ROOT.TCanvas()\n",
    "h2b.Draw(\"COLZ\")\n",
    "c.Draw()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "c = ROOT.TCanvas()\n",
    "h2c.Draw(\"COLZ\")\n",
    "c.Draw()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "c = ROOT.TCanvas()\n",
    "h2d.Draw(\"COLZ\")\n",
    "c.Draw()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": [
    "c = ROOT.TCanvas()\n",
    "h2e.SetStats(0)\n",
    "h2e.SetTitle(\"\")\n",
    "h2e.GetXaxis().SetTitle(\"gen 1/p_{T} [1/GeV]\")\n",
    "h2e.GetYaxis().SetTitle(\"#Delta(p_{T})/p_{T}\")\n",
    "#h2e.GetYaxis().SetRangeUser(-1, 2)\n",
    "h2e.Draw(\"COLZ\")\n",
    "c.Draw()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "c = ROOT.TCanvas()\n",
    "\n",
    "hname = \"h2e\"\n",
    "h = h2e.Clone(\"h2e_clone\")\n",
    "#h.Draw(\"COLZ\")\n",
    "#gPad.Print(hname+\".png\")\n",
    "#h.RebinX(2)\n",
    "\n",
    "#h_pfx = h.ProfileX(hname+\"_pfx\", 1, -1, \"s\")\n",
    "#h_pfx.SetMaximum(1.2)\n",
    "#h_pfx.SetMinimum(-0.2)\n",
    "#h_pfx.Draw()\n",
    "#h_pfx.Fit(\"pol1\", \"\", \"\", 0.025, 0.2499)\n",
    "#gPad.Print(h_pfx.GetName()+\".png\")\n",
    "#\n",
    "\n",
    "if True:\n",
    "  # Apply gaussian fits\n",
    "  gr1 = ROOT.TGraphAsymmErrors(h.GetNbinsX())\n",
    "  gr2 = ROOT.TGraphAsymmErrors(h.GetNbinsX())\n",
    "  gr1_aspt = ROOT.TGraphAsymmErrors(h.GetNbinsX())\n",
    "  gr2_aspt = ROOT.TGraphAsymmErrors(h.GetNbinsX())\n",
    "  for i in xrange(h.GetNbinsX()):\n",
    "    h_py = h.ProjectionY(\"_py\", i+1, i+1)\n",
    "    if h_py.Integral() < 15:  continue\n",
    "    #r = h_py.Fit(\"gaus\", \"SNQ\")\n",
    "    r = h_py.Fit(\"gaus\", \"SNQ\", \"\", h_py.GetMean() - 0.04*8, h_py.GetMean() + 0.04*8)\n",
    "    mean, sigma, meanErr, sigmaErr = r.Parameter(1), r.Parameter(2), r.ParError(1), r.ParError(2)\n",
    "    gr1.SetPoint(i, h.GetXaxis().GetBinCenter(i+1), mean)\n",
    "    gr1.SetPointError(i, 0, 0, sigma, sigma)\n",
    "    gr2.SetPoint(i, h.GetXaxis().GetBinCenter(i+1), sigma)\n",
    "    gr2.SetPointError(i, 0, 0, sigmaErr, sigmaErr)\n",
    "    gr1_aspt.SetPoint(i, 1.0/h.GetXaxis().GetBinCenter(i+1), mean)\n",
    "    gr1_aspt.SetPointError(i, 0, 0, sigma, sigma)\n",
    "    gr2_aspt.SetPoint(i, 1.0/h.GetXaxis().GetBinCenter(i+1), sigma)\n",
    "    gr2_aspt.SetPointError(i, 0, 0, sigmaErr, sigmaErr)\n",
    "  #\n",
    "  hname1 = hname\n",
    "  h_pfx = h.ProfileX(hname1+\"_pfx\", 1, -1, \"s\")\n",
    "  h_pfx.Reset()\n",
    "  h_pfx.SetMaximum(1.2)\n",
    "  h_pfx.SetMinimum(-0.2)\n",
    "  h_pfx.Draw()\n",
    "  gr1.SetMarkerStyle(20)\n",
    "  gr1.Draw(\"p\")\n",
    "  #gr1.Fit(\"pol1\", \"\", \"\", 0.025, 0.2499)\n",
    "  #gPad.Print(h_pfx.GetName()+\".png\")\n",
    "  #\n",
    "  hname2 = hname\n",
    "  h_pfx = h.ProfileX(hname2+\"_pfx\", 1, -1, \"s\")\n",
    "  h_pfx.Reset()\n",
    "  h_pfx.SetMaximum(1)\n",
    "  h_pfx.SetMinimum(0)\n",
    "  h_pfx.Draw()\n",
    "  gr2.SetMarkerStyle(20)\n",
    "  gr2.Draw(\"p\")\n",
    "  #gr2.Fit(\"pol1\", \"\", \"\", 0.025, 0.2499)\n",
    "  #gPad.Print(h_pfx.GetName()+\".png\")\n",
    "  #\n",
    "  hname1 = hname\n",
    "  h_pfx = h.ProfileX(hname1+\"_pfx\", 1, -1, \"s\")\n",
    "  h_pfx.Reset()\n",
    "  h_pfx.SetBins(50, 0, 50)\n",
    "  h_pfx.GetXaxis().SetTitle(\"gen p_{T} [GeV]\")\n",
    "  h_pfx.GetYaxis().SetTitle(\"#Delta(p_{T})/p_{T} bias\")\n",
    "  h_pfx.SetMaximum(1.2)\n",
    "  h_pfx.SetMinimum(-0.2)\n",
    "  h_pfx.Draw()\n",
    "  gr1_aspt.SetMarkerStyle(20)\n",
    "  gr1_aspt.Draw(\"p\")\n",
    "  #gr1_aspt.Fit(\"pol1\", \"\", \"\", 0.025, 0.2499)\n",
    "  #ROOT.gPad.SetLogx(1)\n",
    "  #ROOT.gPad.Print(h_pfx.GetName()+\".png\")\n",
    "  #ROOT.gPad.SetLogx(0)\n",
    "  #\n",
    "  hname2 = hname\n",
    "  h_pfx = h.ProfileX(hname2+\"_pfx\", 1, -1, \"s\")\n",
    "  h_pfx.Reset()\n",
    "  h_pfx.SetStats(0)\n",
    "  h_pfx.SetBins(50, 0, 50)\n",
    "  h_pfx.GetXaxis().SetTitle(\"gen p_{T} [GeV]\")\n",
    "  h_pfx.GetYaxis().SetTitle(\"#Delta(p_{T})/p_{T} resolution\")\n",
    "  h_pfx.SetMaximum(1.2)\n",
    "  h_pfx.SetMinimum(-0.2)\n",
    "  #h_pfx.SetMaximum(0.1)\n",
    "  #h_pfx.SetMinimum(-0.01)\n",
    "  h_pfx.Draw()\n",
    "  gr2_aspt.SetMarkerStyle(20)\n",
    "  gr2_aspt.Draw(\"p\")\n",
    "  #gr2_aspt.Fit(\"pol1\", \"\", \"\", 0.025, 0.2499)\n",
    "  #ROOT.gPad.SetLogx(1)\n",
    "  #ROOT.gPad.Print(h_pfx.GetName()+\".png\")\n",
    "  #ROOT.gPad.SetLogx(0)\n",
    "    \n",
    "c.Draw()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# For classification\n",
    "hh1a = ROOT.TH1F(\"hh1a\", \"hh1a\", 120, -0.1, 1.1)\n",
    "hh1b = ROOT.TH1F(\"hh1b\", \"hh1b\", 120, -0.1, 1.1)\n",
    "\n",
    "for i in xrange(nentries_test):\n",
    "  if y_test[1][i] != 100.:  # mask_value is set to 100\n",
    "    hh1a.Fill(y_test_meas[1][i])\n",
    "\n",
    "for i in xrange(y_adv_test[1].shape[0]):\n",
    "  hh1b.Fill(y_adv_test_meas[1][i])\n",
    "\n",
    "\n",
    "c = ROOT.TCanvas()\n",
    "hh1a.SetLineColor(632)  # kRed\n",
    "hh1a.Scale(1.0/hh1a.Integral())\n",
    "hh1a.Draw(\"hist\")\n",
    "hh1b.SetLineColor(1)  # kBlack\n",
    "hh1b.Scale(1.0/hh1b.Integral())\n",
    "hh1b.Draw(\"same hist\")\n",
    "c.Draw()\n",
    "c.SetLogy()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "try:\n",
    "  y_true = np.concatenate((y_test[1][:nentries_test], y_adv_test[1]))\n",
    "except ValueError:\n",
    "  y_true = np.concatenate((y_test[1][:nentries_test, np.newaxis], y_adv_test[1]))\n",
    "y_pred = np.concatenate((y_test_meas[1], y_adv_test_meas[1]))\n",
    "y_pred_0 = np.concatenate((y_test_meas[0], y_adv_test_meas[0]))\n",
    "\n",
    "mask = (y_true != 100.)  # mask_value is set to 100\n",
    "y_true = y_true[mask]\n",
    "y_pred = y_pred[mask]\n",
    "y_pred_0 = y_pred_0[mask]\n",
    "\n",
    "mask = np.abs(1.0/y_pred_0) > discr_pt_cut\n",
    "y_true = y_true[mask]\n",
    "y_pred = y_pred[mask]\n",
    "y_pred_0 = y_pred_0[mask]\n",
    "\n",
    "\n",
    "fpr, tpr, thresh = roc_curve(y_true, y_pred)\n",
    "\n",
    "fig, ax = plt.subplots(tight_layout=True)\n",
    "ax.plot(fpr, tpr)\n",
    "ax.set_xlabel('False positive rate')\n",
    "ax.set_ylabel('True positive rate')\n",
    "ax.set_title('ROC curve')\n",
    "ax.set_xlim([0.0,1.0])\n",
    "ax.set_ylim([0.9,1.0])\n",
    "\n",
    "idx = np.searchsorted(tpr, [0.9, 0.925, 0.95, 0.97, 0.98, 0.985, 0.99, 0.995])\n",
    "print tpr[idx]\n",
    "print fpr[idx]\n",
    "print thresh[idx]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Build trigger ####\n",
    "\n",
    "pt_bins = (-0.50, -0.333333, -0.25, -0.20, -0.15, -0.10, -0.05, 0.05, 0.10, 0.15, 0.20, 0.25, 0.333333, 0.50)\n",
    "def find_pt_bin(pt):\n",
    "  ipt = np.digitize((pt,), pt_bins[1:])[0]  # skip lowest edge\n",
    "  ipt = np.clip(ipt, 0, len(pt_bins)-2)\n",
    "  return ipt\n",
    "def emtf_road_quality(ipt):\n",
    "  best_ipt = find_pt_bin(0.)\n",
    "  return best_ipt - abs(ipt - best_ipt)\n",
    "\n",
    "class MyTriggerV1(object):\n",
    "  \n",
    "  def __init__(self):\n",
    "    pass\n",
    "\n",
    "  def get_trigger_pt(self, y_meas):\n",
    "    pt = np.abs(1.0/y_meas)\n",
    "    pt_clipped = np.clip(pt, 3., 60.)\n",
    "    pt = pt * (1.0 + (0.08813 + 0.009504 * pt_clipped) * 1.28155)  # erf(1.28155/sqrt(2)) = 0.8 [90% upper limit from -1 to -1]\n",
    "    return pt\n",
    "  \n",
    "  def pass_trigger(self, x, ndof, y_meas, y_discr):\n",
    "    trk_mode = 0\n",
    "    x_mode_vars = np.equal(x[nlayers*5+3:nlayers*5+8], 1)\n",
    "    for i, x_mode_var in enumerate(x_mode_vars):\n",
    "      if i == 0:\n",
    "        station = 1\n",
    "      else:\n",
    "        station = i\n",
    "      if x_mode_var:\n",
    "        trk_mode |= (1 << (4 - station))\n",
    "\n",
    "    ipt1 = (x[nlayers*5+0:nlayers*5+1] * 6 + 6).astype(np.int32)\n",
    "    ipt2 = find_pt_bin(y_meas)\n",
    "    quality1 = emtf_road_quality(ipt1)\n",
    "    quality2 = emtf_road_quality(ipt2)\n",
    "    \n",
    "    if trk_mode in (11,13,14,15) and quality2 <= (quality1+1):\n",
    "      if np.abs(1.0/y_meas) > discr_pt_cut:\n",
    "        if ndof <= 3:\n",
    "          #trigger = (y_discr > 0.5)\n",
    "          trigger = (y_discr > 0.8)\n",
    "          #trigger = (y_discr > 0.95)\n",
    "        else:\n",
    "          trigger = (y_discr > 0.5393)\n",
    "          #trigger = (y_discr > 0.95)\n",
    "      else:\n",
    "        trigger = True\n",
    "    else:\n",
    "      trigger = False\n",
    "    return trigger\n",
    "\n",
    "\n",
    "class MyTriggerV2(object):\n",
    "  \n",
    "  def __init__(self):\n",
    "    pass\n",
    "\n",
    "  def get_trigger_pt(self, x, y_meas):\n",
    "    zone = int(x[(nlayers*5) + 1] * 5)\n",
    "    \n",
    "    pt = np.abs(1.0/y_meas)\n",
    "    pt_clipped = np.clip(pt, 3., 60.)\n",
    "    #pt = pt * (1.0 + (0.081 + 0.009 * pt_clipped) * 1.28155)  # erf(1.28155/sqrt(2)) = 0.8 [90% upper limit from -1 to -1]\n",
    "    #pt = pt * (1.0 + (0.080 + 0.0051 * pt_clipped) * 1.28155)  # erf(1.28155/sqrt(2)) = 0.8 [90% upper limit from -1 to -1]\n",
    "    #pt = pt * (1.0 + (0.18643468 + 0.00983759 * pt_clipped))\n",
    "    #pt = pt * (1.0 + (0.19061872 + 0.00897454 * pt_clipped))\n",
    "    #pt = pt * (1.0 + (0.21251148 + 0.00658309 * 0.97 * pt_clipped))\n",
    "    #pt = pt * (1.0 + (0.21540622 + 0.00588042 * 0.97 * pt_clipped))\n",
    "    #pt = pt * (1.0 + (0.23736955 + 0.00444597 * pt_clipped))\n",
    "    \n",
    "    sf =[[  0.00000000e+00,   2.49868810e-01,   9.67491604e-03],\n",
    "         [  1.00000000e+00,   2.02819258e-01,   3.44642927e-03],\n",
    "         [  2.00000000e+00,   1.34788156e-01,   3.97331361e-03],\n",
    "         [  3.00000000e+00,   1.34788156e-01,   3.97331361e-03],\n",
    "         [  4.00000000e+00,   2.05471098e-01,   7.20871985e-03],\n",
    "         [  5.00000000e+00,   2.05471098e-01,   7.20871985e-03]]\n",
    "    \n",
    "    sf =[[  0.00000000e+00,   2.63994873e-01,   9.85030923e-03],\n",
    "         [  1.00000000e+00,   1.79664418e-01,   5.61202876e-03],\n",
    "         [  2.00000000e+00,   1.62771225e-01,   2.96276459e-03],\n",
    "         [  3.00000000e+00,   1.62771225e-01,   2.96276459e-03],\n",
    "         [  4.00000000e+00,   1.40744388e-01,   6.65116590e-03],\n",
    "         [  5.00000000e+00,   1.40744388e-01,   6.65116590e-03]] \n",
    "\n",
    "    a, b = sf[zone][1], sf[zone][2]\n",
    "    pt = pt * (1.0 + (a + b * pt_clipped))\n",
    "    return pt\n",
    "  \n",
    "  def pass_trigger(self, x, ndof, y_meas, y_discr):\n",
    "    trk_mode = 0\n",
    "    x_mode_vars = np.equal(x[nlayers*5+3:nlayers*5+8], 1)\n",
    "    for i, x_mode_var in enumerate(x_mode_vars):\n",
    "      if i == 0:\n",
    "        station = 1\n",
    "      else:\n",
    "        station = i\n",
    "      if x_mode_var:\n",
    "        trk_mode |= (1 << (4 - station))\n",
    "\n",
    "    straightness = int(x[(nlayers*5) + 0] * 6) + 6\n",
    "    \n",
    "    ipt1 = straightness\n",
    "    ipt2 = find_pt_bin(y_meas)\n",
    "    quality1 = emtf_road_quality(ipt1)\n",
    "    quality2 = emtf_road_quality(ipt2)\n",
    "    \n",
    "    if trk_mode in (11,13,14,15) and quality2 <= (quality1+1):\n",
    "      if np.abs(1.0/y_meas) > discr_pt_cut:\n",
    "        if ndof <= 3:\n",
    "          #trigger = (y_discr > 0.8)\n",
    "          trigger = (y_discr > 0.996)\n",
    "        else:\n",
    "          #trigger = (y_discr > 0.5393)\n",
    "          trigger = (y_discr > 0.992)\n",
    "      else:\n",
    "        trigger = (y_discr >= 0.)  # True\n",
    "    else:\n",
    "      trigger = (y_discr < 0.)  # False\n",
    "    return trigger\n",
    "\n",
    "# ______________________________________________________________________________\n",
    "mytrigger = MyTriggerV2()\n",
    "\n",
    "from rootpy.plotting import Hist, Efficiency\n",
    "from math import sqrt\n",
    "histograms = {}\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Make trigger efficiency ####\n",
    "\n",
    "eff_pt_bins = (0., 0.5, 1., 2., 3., 4., 5., 6., 8., 10., 12., 14., 16., 18., 20., 22., 24., 26., 28., 30., 35., 40., 45., 50., 60., 80., 120.)\n",
    "\n",
    "hname = \"x_eff_vs_genpt_denom\"\n",
    "h1c_denom = Hist(eff_pt_bins, name=hname, title=\"; gen p_{T} [GeV]\", type='F')\n",
    "hname = \"x_eff_vs_genpt_l1pt10\"\n",
    "h1c_numer_1 = Hist(eff_pt_bins, name=hname, title=\"; gen p_{T} [GeV]\", type='F')\n",
    "hname = \"x_eff_vs_genpt_l1pt20\"\n",
    "h1c_numer_2 = Hist(eff_pt_bins, name=hname, title=\"; gen p_{T} [GeV]\", type='F')\n",
    "hname = \"x_eff_vs_genpt_l1pt30\"\n",
    "h1c_numer_3 = Hist(eff_pt_bins, name=hname, title=\"; gen p_{T} [GeV]\", type='F')\n",
    "hname = \"x_eff_vs_genpt_l1pt40\"\n",
    "h1c_numer_4 = Hist(eff_pt_bins, name=hname, title=\"; gen p_{T} [GeV]\", type='F')\n",
    "hname = \"x_eff_vs_genpt_l1pt50\"\n",
    "h1c_numer_5 = Hist(eff_pt_bins, name=hname, title=\"; gen p_{T} [GeV]\", type='F')\n",
    "\n",
    "h1c_data = []\n",
    "\n",
    "# Loop over events\n",
    "for x, ndof, y_meas, y_discr, y_true in zip(x_test, x_test, y_test_meas[0], y_test_meas[1], y_test[0]):\n",
    "\n",
    "  ndof = 4  #FIXME\n",
    "  \n",
    "  zone = int(x[(nlayers*5) + 1] * 5)\n",
    "  \n",
    "  trigger = mytrigger.pass_trigger(x, ndof, y_meas, y_discr)\n",
    "  \n",
    "  #pt = mytrigger.get_trigger_pt(y_meas)\n",
    "  pt = mytrigger.get_trigger_pt(x, y_meas)\n",
    "  pt_true = np.abs(1.0/y_true)\n",
    "  \n",
    "  h1c_denom.fill(pt_true)\n",
    "  if trigger and (pt > 10.):\n",
    "    h1c_numer_1.fill(pt_true)\n",
    "  if trigger and (pt > 20.):\n",
    "    h1c_numer_2.fill(pt_true)\n",
    "  if trigger and (pt > 30.):\n",
    "    h1c_numer_3.fill(pt_true)\n",
    "  if trigger and (pt > 40.):\n",
    "    h1c_numer_4.fill(pt_true)\n",
    "  if trigger and (pt > 50.):\n",
    "    h1c_numer_5.fill(pt_true)\n",
    "    \n",
    "  if trigger:\n",
    "    h1c_data.append((zone, np.asscalar(np.abs(1.0/y_true)), np.asscalar(np.abs(1.0/y_meas))))\n",
    "\n",
    "h1c_eff = Efficiency(h1c_numer_2, h1c_denom)\n",
    "h1c_eff.SetStatisticOption(0)  # kFCP\n",
    "h1c_eff.SetConfidenceLevel(0.682689492137)  # one sigma\n",
    "h1c_eff.SetMarkerStyle(1)\n",
    "h1c_eff.SetMarkerColor(800)  # kOrange\n",
    "h1c_eff.SetLineColor(800)  # kOrange\n",
    "h1c_eff.SetLineWidth(2)\n",
    "h1c_eff.SetDirectory(0)\n",
    "histograms['h1c_numer_1'] = h1c_numer_1\n",
    "histograms['h1c_numer_2'] = h1c_numer_2\n",
    "histograms['h1c_numer_3'] = h1c_numer_3\n",
    "histograms['h1c_numer_4'] = h1c_numer_4\n",
    "histograms['h1c_numer_5'] = h1c_numer_5\n",
    "histograms['h1c_denom'] = h1c_denom\n",
    "histograms['h1c_eff'] = h1c_eff\n",
    "\n",
    "for xx, pt in [(h1c_numer_1, 10.), (h1c_numer_2, 20.), (h1c_numer_3, 30.), (h1c_numer_4, 40.), (h1c_numer_5, 50.)]:\n",
    "  b = xx.FindBin(pt+0.5)\n",
    "  print pt, xx.GetBinContent(b)/h1c_denom.GetBinContent(b)\n",
    "\n",
    "# Add corrections\n",
    "if False:\n",
    "  nbinsx = h1c_eff.GetTotalHistogram().GetNbinsX()\n",
    "  corrections = [0.0, 0.0, 0.0, 2.5596844660416443e-05, 9.071900979369844e-05, -0.00025407866698875234, 3.9318943372533294e-05, 0.00046750609322471475, -0.0012868531325132167, -0.0017629378199139414, -0.003412967281340079, -1.859263302672609e-05, -0.0027697063960877566, -0.011912089953303617, -0.012565904385017701, -0.01502952024543791, -0.007091832957321742, -0.011625792518549893, -0.017156862745097978, -0.007722007722007707, -0.008966446308134701, -0.00857140366324638, -0.021269462895507463, -0.009598486441034226, -0.01485925792486198, -0.010991760558270336]\n",
    "  assert(len(corrections) == nbinsx)\n",
    "  for b in xrange(1,nbinsx+1):\n",
    "    old_eff = h1c_eff.GetEfficiency(b)\n",
    "    new_eff = old_eff + corrections[b-1]\n",
    "    h1c_eff.GetPassedHistogram().SetBinContent(b, h1c_eff.GetTotalHistogram().GetBinContent(b) * new_eff)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "infile1 = ROOT.TFile.Open(\"emtf_eff_vs_genpt_l1pt20.root\")\n",
    "frame = infile1.Get(\"emtf_eff_vs_genpt_l1pt20_denom_clone\")\n",
    "h1a_eff = infile1.Get(\"emtf_eff_vs_genpt_l1pt20_denom_clone\")\n",
    "h1b_eff = infile1.Get(\"emtf2023_eff_vs_genpt_l1pt20_denom_clone\")\n",
    "\n",
    "c = ROOT.TCanvas()\n",
    "frame.Draw()\n",
    "h1a_eff.Draw(\"same\")\n",
    "h1b_eff.Draw(\"same\")\n",
    "h1c_eff.Draw(\"same\")\n",
    "c.Draw()\n",
    "\n",
    "# Find corrections\n",
    "if False:\n",
    "  nbinsx = h1c_eff.GetTotalHistogram().GetNbinsX()\n",
    "  corrections = []\n",
    "  for b in xrange(1,nbinsx+1):\n",
    "    eff1 = h1b_eff.GetEfficiency(b)\n",
    "    eff2 = h1c_eff.GetEfficiency(b)\n",
    "    corr = eff1 - eff2\n",
    "    corrections.append(corr)\n",
    "  print corrections"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Find pT scale factor\n",
    "\n",
    "if True:\n",
    "  from sklearn import linear_model\n",
    "  \n",
    "  h1c_data = np.asarray(h1c_data)\n",
    "  \n",
    "  h1c_data_zone = h1c_data[:,0].astype(np.int32)\n",
    "  \n",
    "  fig, axs = plt.subplots(2, 3, figsize=(4*3,4*2), tight_layout=True)\n",
    "  myscales = []\n",
    "  \n",
    "  for zone in xrange(6):  # 6 zones\n",
    "    h1c_data_sf = []\n",
    "\n",
    "    #for pt in np.linspace(12, 32, 6):  # 4 GeV bin size\n",
    "    for pt in np.linspace(14, 30, 5):  # 4 GeV bin size\n",
    "      if zone == 4 or zone == 5:\n",
    "        sel = ((h1c_data_zone == 4) | (h1c_data_zone == 5))  & ((pt-2) <= h1c_data[:, 1]) & (h1c_data[:, 1] < (pt+2))\n",
    "      elif zone == 2 or zone == 3:\n",
    "        sel = ((h1c_data_zone == 2) | (h1c_data_zone == 3))  & ((pt-2) <= h1c_data[:, 1]) & (h1c_data[:, 1] < (pt+2))\n",
    "      else:\n",
    "        sel = (h1c_data_zone == zone) & ((pt-2) <= h1c_data[:, 1]) & (h1c_data[:, 1] < (pt+2))\n",
    "      #sel = ((pt-2) < h1c_data[:, 1]) & (h1c_data[:, 1] < (pt+2))\n",
    "      data = h1c_data[sel]\n",
    "      data = data[:,1] / data[:,2]  # pt_true/pt_xml\n",
    "      sf = np.percentile(data, [90.5], overwrite_input=True)\n",
    "      h1c_data_sf.append((pt, np.asscalar(sf)))\n",
    "    \n",
    "    # Fit\n",
    "    h1c_data_sf = np.asarray(h1c_data_sf)\n",
    "    h1c_x = h1c_data_sf[:,0][:, np.newaxis]\n",
    "    h1c_y = h1c_data_sf[:,1] - 1.0\n",
    "    linreg = linear_model.LinearRegression()\n",
    "    linreg.fit(h1c_x, h1c_y)\n",
    "    myscales.append((zone, linreg.intercept_, linreg.coef_[0]))\n",
    "    _ = axs[(zone/3, zone%3)].scatter(h1c_x, h1c_y)\n",
    "    _ = axs[(zone/3, zone%3)].plot(h1c_x, linreg.predict(h1c_x))\n",
    "\n",
    "  print np.array2string(np.array(myscales, dtype=np.float32), separator=', ')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Make trigger rates ####\n",
    "\n",
    "hname = \"highest_x_absEtaMin0_absEtaMax2.5_qmin12_pt\"\n",
    "rates_hist = Hist(100, 0., 100., name=hname, title=\"; p_{T} [GeV]; entries\", type='F')\n",
    "\n",
    "rates_nevents = 2000\n",
    "rates_njobs = 100\n",
    "rates_array = np.zeros((rates_njobs,rates_nevents), dtype=np.float32)\n",
    "\n",
    "for x, ndof, y_meas, y_discr, aux in zip(x_adv_test, x_adv_test, y_adv_test_meas[0], y_adv_test_meas[1], aux_adv_test):\n",
    "  \n",
    "  ndof = 4  #FIXME\n",
    "  \n",
    "  (jobid, ievt, highest_part_pt, highest_track_pt) = aux\n",
    "  jobid = int(jobid)\n",
    "  ievt = int(ievt)\n",
    "  \n",
    "  #pt = mytrigger.get_trigger_pt(y_meas)\n",
    "  pt = mytrigger.get_trigger_pt(x, y_meas)\n",
    "  \n",
    "  trigger = mytrigger.pass_trigger(x, ndof, y_meas, y_discr)\n",
    "\n",
    "  if trigger:\n",
    "    rates_array[jobid,ievt] = max(rates_array[jobid,ievt], pt)\n",
    "\n",
    "rates_nevents_1 = 0\n",
    "\n",
    "for jobid in xrange(rates_array.shape[0]):\n",
    "  if rates_array[jobid].sum() > 0.:\n",
    "    for ievt in xrange(rates_array.shape[1]):\n",
    "      x = rates_array[jobid,ievt]\n",
    "      if x > 0.:\n",
    "        highest_pt = min(100.-1e-3, x)\n",
    "        rates_hist.fill(highest_pt)\n",
    "    rates_nevents_1 += rates_nevents\n",
    "\n",
    "print rates_nevents * rates_njobs, rates_nevents_1\n",
    "\n",
    "\n",
    "def make_ptcut(h):\n",
    "  use_overflow = True\n",
    "  binsum = 0\n",
    "  binerr2 = 0\n",
    "  for ib in xrange(h.GetNbinsX()+2-1, 0-1, -1):\n",
    "    if (not use_overflow) and (ib == 0 or ib == h.GetNbinsX()+1):\n",
    "      continue\n",
    "    binsum += h.GetBinContent(ib)\n",
    "    binerr2 += h.GetBinError(ib)**2\n",
    "    h.SetBinContent(ib, binsum)\n",
    "    h.SetBinError(ib, sqrt(binerr2))\n",
    "  return\n",
    "\n",
    "def make_rate(h, nevents):\n",
    "  orbitFreq = 11245.6\n",
    "  nCollBunches = 1866\n",
    "  nZeroBiasEvents = nevents\n",
    "  convFactorToHz = orbitFreq * nCollBunches / nZeroBiasEvents\n",
    "  h.Scale(convFactorToHz / 1000.)\n",
    "  return\n",
    "\n",
    "make_ptcut(rates_hist)\n",
    "make_rate(rates_hist, rates_nevents_1)\n",
    "\n",
    "rates_hist.SetLineColor(800)  # kOrange\n",
    "rates_hist.SetLineWidth(2)\n",
    "rates_hist.SetDirectory(0)\n",
    "histograms['rates_hist'] = rates_hist"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "c = ROOT.TCanvas()\n",
    "rates_hist.Draw(\"hist\")\n",
    "c.SetLogy()\n",
    "c.Draw()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Rates ####\n",
    "\n",
    "infile2 = ROOT.TFile.Open(\"emtf2023_rate_reduction.root\")\n",
    "#cc1 = infile2.Get(\"cc1\")\n",
    "denom = infile2.Get(\"denom\")\n",
    "numer = infile2.Get(\"numer\")\n",
    "ratio = infile2.Get(\"ratio\")\n",
    "\n",
    "rates_hist_ratio = rates_hist.Clone(\"ratio2\")\n",
    "rates_hist_ratio.Divide(rates_hist_ratio, denom, 1, 1, \"\")\n",
    "\n",
    "cc1 = ROOT.TCanvas(\"cc1\", \"cc1\", 600, 700)\n",
    "cc1.Divide(1,2)\n",
    "cc1_1 = cc1.GetPad(1)\n",
    "cc1_1.SetPad(0.01,0.25,0.99,0.99)\n",
    "cc1_1.SetBottomMargin(0.01)\n",
    "cc1_1.SetGrid()\n",
    "cc1_1.SetLogy()\n",
    "cc1_2 = cc1.GetPad(2)\n",
    "cc1_2.SetPad(0.01,0.01,0.99,0.25)\n",
    "cc1_2.SetTopMargin(0.01)\n",
    "cc1_2.SetBottomMargin(0.43)\n",
    "cc1_2.SetGrid()\n",
    "\n",
    "cc1_1.cd()\n",
    "denom.Draw(\"hist\")\n",
    "numer.Draw(\"hist same\")\n",
    "rates_hist.Draw(\"hist same\")\n",
    "cc1_2.cd()\n",
    "ratio.Draw(\"hist same\")\n",
    "rates_hist_ratio.Draw(\"hist same\")\n",
    "cc1.Draw()\n",
    "\n",
    "print denom.GetBinContent(denom.FindBin(20.)), numer.GetBinContent(numer.FindBin(20.)), rates_hist.GetBinContent(rates_hist.FindBin(20.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# from https://github.com/keras-team/keras/issues/4843\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from keras.datasets import mnist\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.metrics import categorical_accuracy\n",
    "from keras.initializers import glorot_uniform, zero\n",
    "\n",
    "\n",
    "input_dim = 28*28\n",
    "output_dim = 10\n",
    "x = K.placeholder(name=\"x\", shape=(None, input_dim))\n",
    "ytrue = K.placeholder(name=\"y\", shape=(None, output_dim))\n",
    "\n",
    "hidden_dim = 128\n",
    "W1 = K.variable(glorot_uniform()([input_dim, hidden_dim]))\n",
    "b1 = K.variable(zero()((hidden_dim,)))\n",
    "W2 = K.variable(glorot_uniform()([hidden_dim, output_dim]))\n",
    "b2 = K.variable(zero()((output_dim,)))\n",
    "params = [W1, b1, W2, b2]\n",
    "\n",
    "\n",
    "hidden = K.sigmoid(K.dot(x, W1)+b1)\n",
    "ypred = K.softmax(K.dot(hidden, W2)+b2)\n",
    "\n",
    "\n",
    "loss = K.mean(K.categorical_crossentropy(ytrue, ypred),axis=None)\n",
    "\n",
    "accuracy = categorical_accuracy(ytrue, ypred)\n",
    "\n",
    "opt = Adam()\n",
    "updates = opt.get_updates(params, [], loss, )\n",
    "train = K.function([x, ytrue],[loss, accuracy],updates=updates)\n",
    "\n",
    "test = K.function([x, ytrue], [loss, accuracy])\n",
    "\n",
    "((xtrain, ytrain),(xtest, ytest)) = mnist.load_data()\n",
    "(xtrain, xtest) = [x.reshape((-1, input_dim))/255.0 for x in (xtrain, xtest)]\n",
    "(ytrain, ytest) = [to_categorical(y, output_dim) for y in (ytrain, ytest)]\n",
    "for epoch in range(1000):\n",
    "\tloss, accuracy = train([xtrain, ytrain])\n",
    "\ttest_loss, test_accuracy = test([xtest, ytest])\n",
    "\tprint(\"Epoch: {}, Train Loss: {}, Train Accuracy: {}, Test Loss: {}, Test Accuracy: {}\".format(\n",
    "\t\tepoch, loss, accuracy, test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "  print x_train.shape, y_train[0].shape, x_mask_train.shape\n",
    "  print np.mean(y_train[0]), np.std(y_train[0]), np.percentile(y_train[0], [2,98])\n",
    "  \n",
    "  fig, axs = plt.subplots(72/4, 4, figsize=(4*4,4*72/4), tight_layout=True)\n",
    "\n",
    "  for i in xrange(x_train.shape[1]):\n",
    "    lay = (i % nlayers)\n",
    "    mask = x_mask_train[...,lay].copy()\n",
    "    if i >= (nlayers*5):\n",
    "      mask *= False\n",
    "    \n",
    "    valid = ~mask\n",
    "    x_i = x_train[valid,i]\n",
    "    y_i = y_train[0][valid,0]\n",
    "\n",
    "    ymin, ymax = -0.6, 0.6\n",
    "    if i < (nlayers*3):\n",
    "      xmin, xmax = -1.5, 1.5\n",
    "    elif i < (nlayers*5):\n",
    "      xmin, xmax = -1.5, 1.5\n",
    "    elif i < 68:\n",
    "      xmin, xmax = -1.5, 1.5\n",
    "    \n",
    "    hist = axs[(i/4, i%4)].hist2d(x_i, y_i, bins=40, range=[[xmin, xmax], [ymin, ymax]], cmap=plt.cm.viridis)  #norm=colors.LogNorm(),\n",
    "    if x_i.size > 0:\n",
    "      print i, np.mean(x_i), np.std(x_i), np.percentile(x_i, [2,98])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "  from sklearn.linear_model import LinearRegression\n",
    "  from sklearn.covariance import EmpiricalCovariance, MinCovDet\n",
    "\n",
    "  #print x_train.shape, y_train[0].shape, x_mask_train.shape\n",
    "\n",
    "  #fig, axs = plt.subplots(72/4, 4, figsize=(4*4,4*72/4), tight_layout=True)\n",
    "  \n",
    "  coefs = np.ones((nlayers * 6) + 4)\n",
    "\n",
    "  for i in xrange(x_train.shape[1]):\n",
    "    lay = (i % nlayers)\n",
    "    mask = x_mask_train[...,lay].copy()\n",
    "    if i >= (nlayers*5):\n",
    "      mask *= False\n",
    "    \n",
    "    valid = ~mask\n",
    "    valid = valid & (np.abs(1.0/y_train[0]) < 14.)  # skip high pT part\n",
    "    x_i = x_train[valid,i].copy()\n",
    "    y_i = y_train[0][valid].copy()\n",
    "    \n",
    "    nentries_test = 100000\n",
    "    x_i = x_i[:nentries_test]\n",
    "    y_i = y_i[:nentries_test]\n",
    "    y_i /= (1.0/np.sqrt(12))  # (b-a)/sqrt(12)\n",
    "    \n",
    "    if x_i.size > 0 and np.std(x_i) > 0.:\n",
    "      coef = 1.0\n",
    "      \n",
    "      # x_phi\n",
    "      if (i < nlayers):\n",
    "        mcd = MinCovDet(assume_centered=True).fit(np.column_stack((x_i,y_i)))\n",
    "        coef = mcd.covariance_[0,1] / mcd.covariance_[0,0]  # Cov[x,y]/Var[x]\n",
    "        print i, coef, np.std(x_i), np.std(x_i * coef), np.std(y_i)\n",
    "        \n",
    "        #lr = LinearRegression(fit_intercept=False).fit(x_i[:,np.newaxis], y_i)\n",
    "        #coef = lr.coef_[0]\n",
    "        #print i, coef, np.std(x_i), np.std(x_i * coef), np.std(y_i)\n",
    "      \n",
    "      # x_theta\n",
    "      elif (nlayers) <= i < (nlayers*2):\n",
    "        if lay == 0 or lay == 1:  # ME1/1 or ME1/2\n",
    "          mcd = MinCovDet(assume_centered=True).fit(np.column_stack((np.abs(x_i),np.abs(y_i))))\n",
    "          coef = mcd.covariance_[0,1] / mcd.covariance_[0,0]  # Cov[x,y]/Var[x]\n",
    "        else:\n",
    "          coef = 1.0/np.std(x_i)\n",
    "        print i, coef, np.std(x_i), np.std(x_i * coef), np.std(y_i)\n",
    "      \n",
    "      # x_bend\n",
    "      elif (nlayers*2) <= i < (nlayers*3):\n",
    "        if lay == 0 or lay == 1:  # ME1/1 or ME1/2\n",
    "          mcd = MinCovDet(assume_centered=True).fit(np.column_stack((x_i,y_i)))\n",
    "          coef = mcd.covariance_[0,1] / mcd.covariance_[0,0]  # Cov[x,y]/Var[x]\n",
    "        else:\n",
    "          coef = 1.0/np.std(x_i)\n",
    "        print i, coef, np.std(x_i), np.std(x_i * coef), np.std(y_i)\n",
    "      \n",
    "      coefs[i] = coef  \n",
    "\n",
    "  print np.array2string(coefs, separator=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "  def huber_loss(y_true, y_pred, delta=1.345):\n",
    "    x = K.abs(y_true - y_pred)\n",
    "    squared_loss = 0.5*K.square(x)\n",
    "    absolute_loss = delta * (x - 0.5*delta)\n",
    "    #xx = K.switch(x < delta, squared_loss, absolute_loss)\n",
    "    xx = tf.where(x < delta, squared_loss, absolute_loss)  # needed for tensorflow\n",
    "    #return K.mean(xx, axis=-1)\n",
    "    return xx\n",
    "\n",
    "\n",
    "  a = y_test[0][:nentries_test].copy()\n",
    "  b = y_test_meas[0].copy()\n",
    "\n",
    "  tmp = np.abs(1.0/a) > 20.\n",
    "  a = a[tmp]\n",
    "  b = b[tmp]\n",
    "\n",
    "  #reg_pt_scale = 14.\n",
    "  #a *= reg_pt_scale\n",
    "  #b *= reg_pt_scale\n",
    "\n",
    "  c = huber_loss(a, b)\n",
    "  sess = tf.InteractiveSession()\n",
    "  d = c.eval()\n",
    "  #sess.close()\n",
    "  e = (a-b).reshape(-1)\n",
    "  f = d.reshape(-1)\n",
    "\n",
    "  print len(a), len(b), a, b\n",
    "  print e, f\n",
    "  print np.min(f), np.max(f), np.median(f)\n",
    "  print 0.5 * np.square(e), 1.345 * e\n",
    "  print len(e), np.equal(0.5 * np.square(e), f).sum()\n",
    "  print np.std(e), np.median(np.abs(e))\n",
    "  \n",
    "  fig, ax = plt.subplots()\n",
    "  ax.set_yscale('log')\n",
    "  _ = ax.hist(e, bins=50, range=[-10,10])\n",
    "\n",
    "  #fig, ax = plt.subplots()\n",
    "  #ax.set_yscale('log')\n",
    "  #_ = ax.hist(0.5 * np.square(e), bins=50, range=[0,10])\n",
    "\n",
    "  fig, ax = plt.subplots()\n",
    "  ax.set_yscale('log')\n",
    "  _ = ax.hist(f, bins=50, range=[0,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "  a = y_test[0][:nentries_test].copy()\n",
    "  b = y_test_meas[0].copy()\n",
    "\n",
    "  tmp = np.abs(1.0/a) > 20.\n",
    "  a = a[tmp]\n",
    "  b = b[tmp]\n",
    "\n",
    "  reg_pt_scale = 14.\n",
    "  a *= reg_pt_scale\n",
    "  b *= reg_pt_scale\n",
    "\n",
    "  c = huber_loss(a, b)\n",
    "  sess = tf.InteractiveSession()\n",
    "  d = c.eval()\n",
    "  #sess.close()\n",
    "  e = (a-b).reshape(-1)\n",
    "  f = d.reshape(-1)\n",
    "\n",
    "  print len(a), len(b), a, b\n",
    "  print e, f\n",
    "  print np.min(f), np.max(f), np.median(f)\n",
    "\n",
    "  fig, ax = plt.subplots()\n",
    "  ax.set_yscale('log')\n",
    "  _ = ax.hist(e, bins=50, range=[-10,10])\n",
    "\n",
    "  #fig, ax = plt.subplots()\n",
    "  #ax.set_yscale('log')\n",
    "  #_ = ax.hist(0.5 * np.square(e), bins=50, range=[0,10])\n",
    "\n",
    "  fig, ax = plt.subplots()\n",
    "  ax.set_yscale('log')\n",
    "  _ = ax.hist(f, bins=50, range=[0,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "  def binary_crossentropy(y_true, y_pred, from_logits=False):\n",
    "    target, output = tf.convert_to_tensor(y_true, np.float32), tf.convert_to_tensor(y_pred, np.float32)\n",
    "\n",
    "    # transform back to logits\n",
    "    if not from_logits:\n",
    "      output = K.clip(output, K.epsilon(), 1 - K.epsilon())\n",
    "      output = K.log(output / (1 - output))\n",
    "\n",
    "    xx =  tf.nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n",
    "    #xx =  tf.nn.weighted_cross_entropy_with_logits(targets=target, logits=output, pos_weight=0.5)  # pos_weight < 1 decreases the false positive count\n",
    "    #return K.mean(xx, axis=-1)\n",
    "    return xx\n",
    "\n",
    "\n",
    "  a1 = y_test[1][:nentries_test].copy()\n",
    "  a2 = y_adv_test[1].copy()\n",
    "\n",
    "  b1 = y_test_meas[1].copy()\n",
    "  b2 = y_adv_test_meas[1].copy()\n",
    "\n",
    "  tmp = (a1 != 100.)\n",
    "  a1 = a1[tmp]\n",
    "  b1 = b1[tmp]\n",
    "\n",
    "  a2 = a2[:,0]\n",
    "  b2 = b2[:,0]\n",
    "  tmp = np.random.randint(0, len(a2), len(a1))\n",
    "  a2 = a2[tmp]\n",
    "  b2 = b2[tmp]\n",
    "\n",
    "  a = np.concatenate((a1, a2))\n",
    "  b = np.concatenate((b1, b2))\n",
    "\n",
    "  c = binary_crossentropy(a, b)\n",
    "  #sess = tf.InteractiveSession()\n",
    "  d = c.eval()\n",
    "  #sess.close()\n",
    "  e = (a-b).reshape(-1)\n",
    "  f = d.reshape(-1)\n",
    "\n",
    "  print len(a1), len(a2), len(b1), len(b2), a1, a2, b1, b2\n",
    "  print len(a), len(b), a, b\n",
    "  print np.min(f), np.max(f), np.median(f)\n",
    "\n",
    "  fig, ax = plt.subplots()\n",
    "  ax.set_yscale('log')\n",
    "  _ = ax.hist(e, bins=50, range=[-10,10])\n",
    "\n",
    "  fig, ax = plt.subplots()\n",
    "  ax.set_yscale('log')\n",
    "  _ = ax.hist(f, bins=50, range=[0,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_h5py():\n",
    "  import h5py\n",
    "\n",
    "  f = h5py.File(model_weights_file)\n",
    "  print f.keys()\n",
    "\n",
    "  keys = [u'dense_1', u'dense_2', u'dense_3', u'regr', u'discr']\n",
    "  for k in keys:\n",
    "    try:\n",
    "      w = f[k][k]['kernel:0'].value\n",
    "      b = f[k][k]['bias:0'].value\n",
    "      print k, w.shape, b.shape, np.min(np.abs(w)), np.max(np.abs(w))\n",
    "      \n",
    "      #FIXME\n",
    "      if k == 'dense_1':\n",
    "        a = np.sum(w*w, axis=0)\n",
    "        b = np.sort(a)/np.sum(a)\n",
    "        print \"..\", a, b\n",
    "    except:\n",
    "      pass\n",
    "\n",
    "if False:\n",
    "  read_h5py()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Current time 2018-07-10 16:47:19.078786\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print('[INFO] Current time {0}'.format(str(datetime.now())))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
